{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('http://fonts.googleapis.com/css?family=Source+Code+Pro');\n",
       "@import url('http://fonts.googleapis.com/css?family=Vollkorn');\n",
       "@import url('http://fonts.googleapis.com/css?family=Arimo');\n",
       "@import url('http://fonts.googleapis.com/css?family=Fira_sans');\n",
       "    \n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "    div.text_cell code {\n",
       "        background: transparent;\n",
       "        color: #000000;\n",
       "        font-weight: 600;\n",
       "        font-size: 12pt;\n",
       "        font-style: bold;\n",
       "        font-family:  'Source Code Pro', Consolas, monocco, monospace;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "\t}\n",
       "\t\n",
       "    div.input_area {\n",
       "        background: #F6F6F9;\n",
       "        border: 1px solid #586e75;\n",
       "    }\n",
       "\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 30pt;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h2 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "        text-align: left;\n",
       "    }\n",
       "    .text_cell_render h2 {\n",
       "        font-weight: 200;\n",
       "        font-size: 16pt;\n",
       "        font-style: italic;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1.5em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h3 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h3 {\n",
       "        font-weight: 200;\n",
       "        font-size: 14pt;\n",
       "        line-height: 100%;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 2em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    }\n",
       "    h4 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h4 {\n",
       "        font-weight: 100;\n",
       "        font-size: 14pt;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    h5 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 200;\n",
       "        font-style: normal;\n",
       "        color: #1d3b84;\n",
       "        font-size: 16pt;\n",
       "        margin-bottom: 0em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: 'Fira sans', verdana,arial,sans-serif;\n",
       "        line-height: 125%;\n",
       "        font-size: 115%;\n",
       "        text-align:justify;\n",
       "        text-justify:inter-word;\n",
       "    }\n",
       "    div.output_wrapper{\n",
       "        margin-top:0.2em;\n",
       "        margin-bottom:0.2em;\n",
       "    }\n",
       "\n",
       "    code{\n",
       "      font-size: 70%;\n",
       "    }\n",
       "    .rendered_html code{\n",
       "    background-color: transparent;\n",
       "    }\n",
       "    ul{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li li{\n",
       "        padding-left: 0.2em; \n",
       "        margin-bottom: 0.2em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    ol{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ol li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "    .rendered_html :hover {\n",
       "       text-decoration: none; \n",
       "    }\n",
       "    .rendered_html :visited {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :focus {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :active {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "    } \n",
       "    hr {\n",
       "      color: #f3f3f3;\n",
       "      background-color: #f3f3f3;\n",
       "      height: 1px;\n",
       "    }\n",
       "    blockquote{\n",
       "      display:block;\n",
       "      background: #fcfcfc;\n",
       "      border-left: 5px solid #c76c0c;\n",
       "      font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "      width:680px;\n",
       "      padding: 10px 10px 10px 10px;\n",
       "      text-align:justify;\n",
       "      text-justify:inter-word;\n",
       "      }\n",
       "      blockquote p {\n",
       "        margin-bottom: 0;\n",
       "        line-height: 125%;\n",
       "        font-size: 100%;\n",
       "      }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "\n",
    "os.chdir( os.path.join('..', 'notebook_format') )\n",
    "from formats import load_style\n",
    "load_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2016-10-30 21:38:03 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.11.1\n",
      "pandas 0.18.1\n",
      "matplotlib 1.5.1\n",
      "gensim 0.13.1\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 8, 6 # change default figure size\n",
    "plt.rcParams['font.size'] = 14 # and font size\n",
    "\n",
    "# 1. magic to print version\n",
    "# 2. magic so that the notebook will reload external python modules\n",
    "%load_ext watermark\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,matplotlib,gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Coherence\n",
    "\n",
    "Topic coherence is a quantitative measure that can be used to compare difference topic models based on their human-interpretability.\n",
    "\n",
    "## Setting up toy corpus\n",
    "\n",
    "The toy corpus essentially has two classes of documents. First five are about human-computer interaction and the other four are about graphs. We will be using the `u_mass` and `c_v` coherence for a \"good\" (trained for 50 iterations) and a \"bad\" (trained for only 1 iteration) LDA model. Intuitively, the good LDA model should be able come up with better or more human-interpretable topics. Therefore the coherence measure for the good LDA model should be better (the higher the better) than that for the bad LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [['human', 'interface', 'computer'],\n",
    "         ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    "         ['eps', 'user', 'interface', 'system'],\n",
    "         ['system', 'human', 'system', 'eps'],\n",
    "         ['user', 'response', 'time'],\n",
    "         ['trees'],\n",
    "         ['graph', 'trees'],\n",
    "         ['graph', 'minors', 'trees'],\n",
    "         ['graph', 'minors', 'survey']]\n",
    "\n",
    "# build the dictionary and convert each document to\n",
    "# bag of words representation\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [ dictionary.doc2bow(text) for text in texts ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the LDA model\n",
    "lda_good = LdaModel(corpus = corpus, id2word = dictionary, iterations = 50, num_topics = 2)\n",
    "lda_bad = LdaModel(corpus = corpus, id2word = dictionary, iterations = 1, num_topics = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "After training the model, we can look at the top words associated with each topic to interpret the meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.173*\"graph\" + 0.168*\"trees\" + 0.115*\"minors\" + 0.079*\"interface\" + 0.077*\"survey\" + 0.070*\"computer\" + 0.064*\"user\" + 0.062*\"human\" + 0.054*\"system\" + 0.050*\"eps\"'),\n",
       " (1,\n",
       "  '0.177*\"system\" + 0.125*\"user\" + 0.099*\"time\" + 0.093*\"response\" + 0.092*\"eps\" + 0.082*\"human\" + 0.076*\"computer\" + 0.070*\"survey\" + 0.069*\"interface\" + 0.041*\"trees\"')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = lda_good.show_topics(num_words = 10)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.156*\"system\" + 0.094*\"user\" + 0.093*\"trees\" + 0.083*\"graph\" + 0.080*\"interface\" + 0.078*\"human\" + 0.076*\"eps\" + 0.072*\"survey\" + 0.071*\"minors\" + 0.070*\"time\"'),\n",
       " (1,\n",
       "  '0.112*\"graph\" + 0.103*\"trees\" + 0.101*\"user\" + 0.088*\"system\" + 0.086*\"computer\" + 0.079*\"response\" + 0.076*\"time\" + 0.075*\"minors\" + 0.074*\"survey\" + 0.070*\"eps\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = lda_bad.show_topics(num_words = 10)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can also use pyLDAvis for interactive web visualization\n",
    "\n",
    "# import pyLDAvis.gensim\n",
    "# pyLDAvis.enable_notebook()\n",
    "# pyLDAvis.gensim.prepare(lda_good, corpus, dictionary)\n",
    "# pyLDAvis.gensim.prepare(lda_bad, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the good LdaModel:\n",
    "\n",
    "- Topic 1: More weight was assigned to words such as \"system\", \"user\", \"eps\", \"interface\" etc which captures the first set of documents.\n",
    "- Topic 2: More weight was assigned to words such as \"graph\", \"trees\", \"survey\" which captures the topic in the second set of documents.\n",
    "\n",
    "As for the badLdaModel:\n",
    "\n",
    "- Topic 1: More weight was assigned to words such as \"system\", \"user\", \"trees\", \"graph\"\n",
    "- Topic 2: More weight wa assigned to words such as \"system\", \"trees\", \"graph\", \"user\" which is similar to the first topic. \n",
    "\n",
    "Looking at the result, we can say the topics generated by the bad LdaMdodel are not clear enough (less human-interpretable). Next, we'll see if the topic coherence measurement's output is consistent with this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_mass\n",
      "good:  -13.2293293715\n",
      "bad:  -14.7183268551\n",
      "\n",
      "c_v\n",
      "good:  0.372857430939\n",
      "bad:  0.361089571831\n"
     ]
    }
   ],
   "source": [
    "# obtain topic coherence using u_mass measure\n",
    "print('u_mass')\n",
    "cm_good1 = CoherenceModel(model = lda_good, corpus = corpus, \n",
    "                         dictionary = dictionary, coherence = 'u_mass')\n",
    "cm_bad1 = CoherenceModel(model = lda_bad, corpus = corpus, \n",
    "                         dictionary = dictionary, coherence = 'u_mass')\n",
    "\n",
    "print( 'good: ', cm_good1.get_coherence() )\n",
    "print( 'bad: ',  cm_bad1.get_coherence() )\n",
    "print()\n",
    "\n",
    "# obtain topic coherence using c_v measure\n",
    "print('c_v')\n",
    "cm_good2 = CoherenceModel(model = lda_good, texts = texts, \n",
    "                          dictionary = dictionary, coherence = 'c_v')\n",
    "cm_bad2 = CoherenceModel(model = lda_bad, texts = texts, \n",
    "                         dictionary = dictionary, coherence = 'c_v')\n",
    "\n",
    "print( 'good: ', cm_good2.get_coherence() )\n",
    "print( 'bad: ', cm_bad2.get_coherence() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `u_mass` and `c_v` coherence for the good LDA model is better than the bad LDA model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import interfaces\n",
    "from gensim.topic_coherence import (segmentation, probability_estimation,\n",
    "                                    direct_confirmation_measure, indirect_confirmation_measure,\n",
    "                                    aggregation)\n",
    "from gensim.matutils import argsort\n",
    "from gensim.utils import is_corpus, FakeDict\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.wrappers import LdaVowpalWabbit, LdaMallet\n",
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "boolean_document_based = ['u_mass']\n",
    "make_pipeline = namedtuple('Coherence_Measure', 'seg, prob, conf, aggr')\n",
    "\n",
    "coherence_dict = {\n",
    "    'u_mass': make_pipeline(segmentation.s_one_pre,\n",
    "                            probability_estimation.p_boolean_document,\n",
    "                            direct_confirmation_measure.log_conditional_probability,\n",
    "                            aggregation.arithmetic_mean)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coherence_Measure(seg=<function s_one_pre at 0x118237ae8>, prob=<function p_boolean_document at 0x118237d08>, conf=<function log_conditional_probability at 0x118237f28>, aggr=<function arithmetic_mean at 0x11823f378>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_dict['u_mass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "topn = 10\n",
    "model = lda_good\n",
    "coherence = 'u_mass'\n",
    "\n",
    "if coherence in boolean_document_based:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = ['human interface computer',\n",
    "         'survey user computer system response time',\n",
    "         'eps user interface system',\n",
    "         'system human system eps',\n",
    "         'user response time',\n",
    "         'trees',\n",
    "         'graph trees',\n",
    "         'graph minors trees',\n",
    "         'graph minors survey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 13)\n"
     ]
    }
   ],
   "source": [
    "count_vec = CountVectorizer(ngram_range = (1, 2), stop_words = 'english', \n",
    "                            min_df = 2, max_df = 0.9, max_features = 10000)\n",
    "\n",
    "X_dtm = count_vec.fit_transform(texts)\n",
    "print(X_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_topics = 2, max_iter = 10, n_jobs = 1)\n",
    "doc_topic_distr = lda.fit_transform(X_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOPWORDS = 15\n",
    "\n",
    "def print_top_words(lda_model, count_vec, n_top_words):\n",
    "    \"\"\"top words associated with each topic for the sklearn LDA model\"\"\"\n",
    "    features = count_vec.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        print( 'Topic #{}:'.format(topic_idx + 1) )\n",
    "        print( ', '.join([ features[i] for i in np.argsort(topic)[-n_top_words:] ]) )\n",
    "        print()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "survey, time, graph minors, minors, response time, response, user, computer, graph, interface, eps, human, trees\n",
      "\n",
      "Topic #2:\n",
      "human, eps, interface, trees, computer, minors, graph minors, response time, response, survey, time, graph, user\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda_model = lda, count_vec = count_vec, n_top_words = TOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [Notebook: Gensim's topic coherence tutorial](http://nbviewer.jupyter.org/github/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_coherence_tutorial.ipynb#topic=2&lambda=1&term=)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
