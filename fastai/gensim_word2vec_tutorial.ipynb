{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2018-05-22 09:28:23 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 6.3.1\n",
      "\n",
      "numpy 1.14.3\n",
      "pandas 0.23.0\n",
      "sklearn 0.19.1\n",
      "matplotlib 2.2.2\n"
     ]
    }
   ],
   "source": [
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# change default style figure and font size\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,sklearn,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed:  420.0902531147003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1aa8fec470>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "start = time()\n",
    "path = '/Users/mingyuliu/Desktop/wiki.ru.vec'\n",
    "model = KeyedVectors.load_word2vec_format(path)\n",
    "end = time()\n",
    "print('elapsed: ', end - start)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1888423"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from subprocess import call\n",
    "\n",
    "\n",
    "def maybe_download(filename, url, expected_bytes):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        call('wget ' + url + filename, shell = True)\n",
    "\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified', filename)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "filename = 'text8.zip'\n",
    "url = 'http://mattmahoney.net/dc/'\n",
    "filename = maybe_download(filename, url, expected_bytes=31344016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "if not os.path.exists(filename.strip('.zip')):\n",
    "    zipfile.ZipFile(filename).extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-20 21:10:16,124 : INFO : collecting all words and their counts\n",
      "2018-05-20 21:10:16,129 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-05-20 21:10:20,024 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2018-05-20 21:10:20,025 : INFO : Loading a fresh vocabulary\n",
      "2018-05-20 21:10:20,187 : INFO : min_count=10 retains 47134 unique words (18% of original 253854, drops 206720)\n",
      "2018-05-20 21:10:20,188 : INFO : min_count=10 leaves 16561031 word corpus (97% of original 17005207, drops 444176)\n",
      "2018-05-20 21:10:20,291 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2018-05-20 21:10:20,300 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2018-05-20 21:10:20,300 : INFO : downsampling leaves estimated 12333563 word corpus (74.5% of prior 16561031)\n",
      "2018-05-20 21:10:20,422 : INFO : estimated required memory for 47134 words and 300 dimensions: 136688600 bytes\n",
      "2018-05-20 21:10:20,422 : INFO : resetting layer weights\n",
      "2018-05-20 21:10:20,985 : INFO : training model with 4 workers on 47134 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-05-20 21:10:21,989 : INFO : EPOCH 1 - PROGRESS: at 7.76% examples, 947473 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:22,995 : INFO : EPOCH 1 - PROGRESS: at 15.81% examples, 965035 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:24,002 : INFO : EPOCH 1 - PROGRESS: at 23.87% examples, 974305 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:25,007 : INFO : EPOCH 1 - PROGRESS: at 31.92% examples, 980473 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:26,017 : INFO : EPOCH 1 - PROGRESS: at 40.09% examples, 985322 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:27,022 : INFO : EPOCH 1 - PROGRESS: at 48.15% examples, 986817 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:28,032 : INFO : EPOCH 1 - PROGRESS: at 56.14% examples, 986032 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:29,038 : INFO : EPOCH 1 - PROGRESS: at 64.26% examples, 987114 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:30,041 : INFO : EPOCH 1 - PROGRESS: at 72.25% examples, 987169 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:31,044 : INFO : EPOCH 1 - PROGRESS: at 80.36% examples, 986482 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:32,050 : INFO : EPOCH 1 - PROGRESS: at 88.54% examples, 987696 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:33,054 : INFO : EPOCH 1 - PROGRESS: at 96.36% examples, 985145 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:33,483 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:10:33,491 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 21:10:33,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:10:33,498 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:10:33,499 : INFO : EPOCH - 1 : training on 17005207 raw words (12331810 effective words) took 12.5s, 985665 effective words/s\n",
      "2018-05-20 21:10:34,504 : INFO : EPOCH 2 - PROGRESS: at 7.94% examples, 968804 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:35,507 : INFO : EPOCH 2 - PROGRESS: at 15.99% examples, 976584 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:36,511 : INFO : EPOCH 2 - PROGRESS: at 23.93% examples, 978279 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:37,514 : INFO : EPOCH 2 - PROGRESS: at 31.92% examples, 981818 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:38,517 : INFO : EPOCH 2 - PROGRESS: at 40.04% examples, 986487 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:39,518 : INFO : EPOCH 2 - PROGRESS: at 48.03% examples, 987159 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:40,520 : INFO : EPOCH 2 - PROGRESS: at 55.97% examples, 986443 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:41,520 : INFO : EPOCH 2 - PROGRESS: at 64.08% examples, 988383 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:42,524 : INFO : EPOCH 2 - PROGRESS: at 72.13% examples, 988962 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:43,525 : INFO : EPOCH 2 - PROGRESS: at 80.25% examples, 988349 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:44,529 : INFO : EPOCH 2 - PROGRESS: at 88.36% examples, 988932 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:45,531 : INFO : EPOCH 2 - PROGRESS: at 96.00% examples, 984696 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:46,029 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:10:46,039 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 21:10:46,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:10:46,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:10:46,049 : INFO : EPOCH - 2 : training on 17005207 raw words (12332086 effective words) took 12.5s, 982866 effective words/s\n",
      "2018-05-20 21:10:47,056 : INFO : EPOCH 3 - PROGRESS: at 7.94% examples, 967031 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:48,060 : INFO : EPOCH 3 - PROGRESS: at 16.11% examples, 982639 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:49,061 : INFO : EPOCH 3 - PROGRESS: at 24.22% examples, 990503 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:50,069 : INFO : EPOCH 3 - PROGRESS: at 32.28% examples, 991778 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:51,071 : INFO : EPOCH 3 - PROGRESS: at 40.27% examples, 991384 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:52,074 : INFO : EPOCH 3 - PROGRESS: at 48.32% examples, 992126 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:53,075 : INFO : EPOCH 3 - PROGRESS: at 56.38% examples, 993024 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:54,080 : INFO : EPOCH 3 - PROGRESS: at 64.55% examples, 994373 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:55,087 : INFO : EPOCH 3 - PROGRESS: at 72.66% examples, 994723 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:56,090 : INFO : EPOCH 3 - PROGRESS: at 80.89% examples, 994705 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:57,094 : INFO : EPOCH 3 - PROGRESS: at 88.95% examples, 994167 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-20 21:10:58,096 : INFO : EPOCH 3 - PROGRESS: at 97.12% examples, 994587 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:10:58,431 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:10:58,439 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 21:10:58,441 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:10:58,445 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:10:58,446 : INFO : EPOCH - 3 : training on 17005207 raw words (12331587 effective words) took 12.4s, 994963 effective words/s\n",
      "2018-05-20 21:10:59,455 : INFO : EPOCH 4 - PROGRESS: at 8.00% examples, 972844 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:00,461 : INFO : EPOCH 4 - PROGRESS: at 16.17% examples, 985083 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:01,462 : INFO : EPOCH 4 - PROGRESS: at 24.10% examples, 984556 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:02,463 : INFO : EPOCH 4 - PROGRESS: at 32.04% examples, 985336 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:03,465 : INFO : EPOCH 4 - PROGRESS: at 40.04% examples, 986656 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:04,467 : INFO : EPOCH 4 - PROGRESS: at 47.91% examples, 984623 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:05,472 : INFO : EPOCH 4 - PROGRESS: at 55.73% examples, 981736 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:06,481 : INFO : EPOCH 4 - PROGRESS: at 63.79% examples, 982589 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:07,486 : INFO : EPOCH 4 - PROGRESS: at 71.78% examples, 982648 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:08,494 : INFO : EPOCH 4 - PROGRESS: at 79.95% examples, 982747 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:09,498 : INFO : EPOCH 4 - PROGRESS: at 88.01% examples, 983071 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:10,501 : INFO : EPOCH 4 - PROGRESS: at 96.12% examples, 984085 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:10,956 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:11:10,963 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-20 21:11:10,964 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:11:10,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:11:10,971 : INFO : EPOCH - 4 : training on 17005207 raw words (12333617 effective words) took 12.5s, 984979 effective words/s\n",
      "2018-05-20 21:11:11,979 : INFO : EPOCH 5 - PROGRESS: at 9.11% examples, 1107987 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:12,982 : INFO : EPOCH 5 - PROGRESS: at 18.46% examples, 1127210 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:13,990 : INFO : EPOCH 5 - PROGRESS: at 27.81% examples, 1136054 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:14,996 : INFO : EPOCH 5 - PROGRESS: at 37.10% examples, 1140085 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:16,003 : INFO : EPOCH 5 - PROGRESS: at 46.03% examples, 1131670 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:17,007 : INFO : EPOCH 5 - PROGRESS: at 55.20% examples, 1131505 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:18,010 : INFO : EPOCH 5 - PROGRESS: at 64.32% examples, 1130509 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:19,011 : INFO : EPOCH 5 - PROGRESS: at 73.37% examples, 1129302 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:20,016 : INFO : EPOCH 5 - PROGRESS: at 82.60% examples, 1127372 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:21,020 : INFO : EPOCH 5 - PROGRESS: at 91.77% examples, 1127222 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:21,908 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:11:21,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 21:11:21,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:11:21,921 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:11:21,922 : INFO : EPOCH - 5 : training on 17005207 raw words (12333109 effective words) took 10.9s, 1126473 effective words/s\n",
      "2018-05-20 21:11:22,926 : INFO : EPOCH 6 - PROGRESS: at 8.82% examples, 1077540 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:23,935 : INFO : EPOCH 6 - PROGRESS: at 17.87% examples, 1090844 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:24,939 : INFO : EPOCH 6 - PROGRESS: at 26.81% examples, 1095512 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:25,941 : INFO : EPOCH 6 - PROGRESS: at 35.68% examples, 1098222 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:26,942 : INFO : EPOCH 6 - PROGRESS: at 44.56% examples, 1098067 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:27,944 : INFO : EPOCH 6 - PROGRESS: at 53.50% examples, 1099255 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:28,946 : INFO : EPOCH 6 - PROGRESS: at 62.49% examples, 1100966 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:29,950 : INFO : EPOCH 6 - PROGRESS: at 71.43% examples, 1101366 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:30,954 : INFO : EPOCH 6 - PROGRESS: at 80.31% examples, 1098256 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:31,958 : INFO : EPOCH 6 - PROGRESS: at 89.30% examples, 1098763 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:32,963 : INFO : EPOCH 6 - PROGRESS: at 98.30% examples, 1098412 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:33,131 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:11:33,138 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 21:11:33,139 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:11:33,146 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:11:33,147 : INFO : EPOCH - 6 : training on 17005207 raw words (12334131 effective words) took 11.2s, 1099103 effective words/s\n",
      "2018-05-20 21:11:34,152 : INFO : EPOCH 7 - PROGRESS: at 8.88% examples, 1083837 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:35,157 : INFO : EPOCH 7 - PROGRESS: at 17.93% examples, 1096126 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:36,160 : INFO : EPOCH 7 - PROGRESS: at 26.93% examples, 1101707 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:37,161 : INFO : EPOCH 7 - PROGRESS: at 35.80% examples, 1103493 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:38,163 : INFO : EPOCH 7 - PROGRESS: at 44.74% examples, 1103420 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:39,169 : INFO : EPOCH 7 - PROGRESS: at 53.73% examples, 1103997 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:40,172 : INFO : EPOCH 7 - PROGRESS: at 62.67% examples, 1103988 words/s, in_qsize 8, out_qsize 1\n",
      "2018-05-20 21:11:41,176 : INFO : EPOCH 7 - PROGRESS: at 71.72% examples, 1105467 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:42,182 : INFO : EPOCH 7 - PROGRESS: at 80.78% examples, 1104305 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:43,184 : INFO : EPOCH 7 - PROGRESS: at 89.77% examples, 1104628 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:44,190 : INFO : EPOCH 7 - PROGRESS: at 98.88% examples, 1104915 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:44,293 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:11:44,299 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 21:11:44,302 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:11:44,306 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:11:44,307 : INFO : EPOCH - 7 : training on 17005207 raw words (12335177 effective words) took 11.2s, 1105529 effective words/s\n",
      "2018-05-20 21:11:45,310 : INFO : EPOCH 8 - PROGRESS: at 8.88% examples, 1085378 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:46,316 : INFO : EPOCH 8 - PROGRESS: at 17.70% examples, 1082098 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:47,324 : INFO : EPOCH 8 - PROGRESS: at 26.75% examples, 1092944 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-20 21:11:48,324 : INFO : EPOCH 8 - PROGRESS: at 35.39% examples, 1089559 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:49,328 : INFO : EPOCH 8 - PROGRESS: at 43.62% examples, 1074599 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:50,330 : INFO : EPOCH 8 - PROGRESS: at 51.73% examples, 1062652 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:51,335 : INFO : EPOCH 8 - PROGRESS: at 59.91% examples, 1054904 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:52,336 : INFO : EPOCH 8 - PROGRESS: at 68.08% examples, 1049097 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:53,342 : INFO : EPOCH 8 - PROGRESS: at 76.43% examples, 1045490 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:54,342 : INFO : EPOCH 8 - PROGRESS: at 84.60% examples, 1040932 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:55,342 : INFO : EPOCH 8 - PROGRESS: at 92.71% examples, 1037030 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:56,199 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:11:56,208 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 21:11:56,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:11:56,215 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:11:56,216 : INFO : EPOCH - 8 : training on 17005207 raw words (12333755 effective words) took 11.9s, 1035893 effective words/s\n",
      "2018-05-20 21:11:57,219 : INFO : EPOCH 9 - PROGRESS: at 8.00% examples, 979338 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:58,219 : INFO : EPOCH 9 - PROGRESS: at 16.23% examples, 994663 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:11:59,226 : INFO : EPOCH 9 - PROGRESS: at 24.40% examples, 998691 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:00,227 : INFO : EPOCH 9 - PROGRESS: at 32.51% examples, 1001774 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:01,230 : INFO : EPOCH 9 - PROGRESS: at 40.68% examples, 1003548 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:02,232 : INFO : EPOCH 9 - PROGRESS: at 48.91% examples, 1005967 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:03,233 : INFO : EPOCH 9 - PROGRESS: at 57.08% examples, 1006673 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:04,239 : INFO : EPOCH 9 - PROGRESS: at 65.31% examples, 1007294 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:05,244 : INFO : EPOCH 9 - PROGRESS: at 73.54% examples, 1008208 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-20 21:12:06,246 : INFO : EPOCH 9 - PROGRESS: at 81.78% examples, 1006739 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:07,247 : INFO : EPOCH 9 - PROGRESS: at 89.95% examples, 1006786 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:08,254 : INFO : EPOCH 9 - PROGRESS: at 98.24% examples, 1006735 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:08,443 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:12:08,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 21:12:08,453 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:12:08,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:12:08,459 : INFO : EPOCH - 9 : training on 17005207 raw words (12333148 effective words) took 12.2s, 1007609 effective words/s\n",
      "2018-05-20 21:12:09,465 : INFO : EPOCH 10 - PROGRESS: at 8.05% examples, 982092 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:10,475 : INFO : EPOCH 10 - PROGRESS: at 16.34% examples, 994429 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:11,487 : INFO : EPOCH 10 - PROGRESS: at 24.22% examples, 984844 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-20 21:12:12,487 : INFO : EPOCH 10 - PROGRESS: at 31.22% examples, 956858 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:13,490 : INFO : EPOCH 10 - PROGRESS: at 39.21% examples, 963717 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:14,490 : INFO : EPOCH 10 - PROGRESS: at 47.33% examples, 970581 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:15,502 : INFO : EPOCH 10 - PROGRESS: at 55.32% examples, 971670 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:16,503 : INFO : EPOCH 10 - PROGRESS: at 63.49% examples, 976471 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:17,512 : INFO : EPOCH 10 - PROGRESS: at 71.72% examples, 980126 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:18,518 : INFO : EPOCH 10 - PROGRESS: at 79.95% examples, 981418 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:19,523 : INFO : EPOCH 10 - PROGRESS: at 88.12% examples, 983214 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:20,530 : INFO : EPOCH 10 - PROGRESS: at 96.36% examples, 985081 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-20 21:12:20,950 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-20 21:12:20,959 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 21:12:20,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 21:12:20,964 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 21:12:20,965 : INFO : EPOCH - 10 : training on 17005207 raw words (12332912 effective words) took 12.5s, 986290 effective words/s\n",
      "2018-05-20 21:12:20,966 : INFO : training on a 170052070 raw words (123331332 effective words) took 120.0s, 1027933 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Text8Corpus, Word2Vec\n",
    "import logging\n",
    "\n",
    "embedding_size = 300\n",
    "sentences = Text8Corpus(filename.strip('.zip'))\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = Word2Vec(sentences, iter=10, min_count=10, size=embedding_size, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.41648173,  0.74130589, -0.01556208, ...,  0.65678674,\n",
       "         0.08788779,  0.63202614],\n",
       "       [-0.78062695,  0.59946221,  0.69510037, ...,  0.28251097,\n",
       "         0.25661314, -0.33165315],\n",
       "       [-0.61705029,  0.14787757,  0.69591302, ...,  0.21548264,\n",
       "         0.51658154,  0.60430765],\n",
       "       ...,\n",
       "       [ 0.04404425,  0.03018282, -0.11842163, ...,  0.16297314,\n",
       "         0.11150454,  0.15189284],\n",
       "       [-0.1586891 ,  0.18594377, -0.03809937, ..., -0.02297424,\n",
       "         0.14540355, -0.07813055],\n",
       "       [-0.00735074, -0.09149278,  0.05290752, ..., -0.06282578,\n",
       "         0.05167256,  0.00352189]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the numpy array of the word vectors\n",
    "vocab_size = len(model.wv.vocab)\n",
    "embeddings = np.zeros((vocab_size, embedding_size))\n",
    "for i in range(vocab_size):\n",
    "    index = model.wv.index2word[i]\n",
    "    embedding_vector = model.wv[index]\n",
    "    embeddings[i] = embedding_vector\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"Extract the first file enclosed in a zip file as a list of words.\"\"\"\n",
    "    with zipfile.ZipFile(filename) as f:\n",
    "        data = f.read(f.namelist()[0]).split()\n",
    "    return data\n",
    "\n",
    "\n",
    "def convert_data_to_index(string_data, wv):\n",
    "    index_data = []\n",
    "    for word in string_data:\n",
    "        if word in wv:\n",
    "            index_data.append(wv.vocab[word].index)\n",
    "    return index_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2413354 ,  0.5821672 ,  0.27155766, -0.22296296, -0.21090697,\n",
       "        0.16287118, -0.6929753 ,  0.03247903, -0.35217708, -0.57623917,\n",
       "        0.6432865 ,  0.6997038 , -0.9982322 , -1.0035763 , -0.24719068,\n",
       "       -0.8779009 , -0.5729689 ,  0.03775633, -0.10416196,  0.57256514,\n",
       "        1.1648967 , -0.05822752,  0.31929407, -0.5414919 ,  0.47587442,\n",
       "        0.3016652 ,  0.49333096,  1.3656893 , -0.7750358 , -0.7581157 ,\n",
       "       -0.73138565,  0.4140502 , -0.46495086,  0.5940104 ,  0.39869294,\n",
       "       -0.17057972,  0.58342224,  0.19809139, -0.59071654,  0.00466528,\n",
       "        1.0200782 ,  0.14507611,  0.71385807, -0.749391  , -0.4471167 ,\n",
       "       -0.34516454, -0.17071487, -0.55398273, -0.2390885 ,  0.89563847,\n",
       "        0.42402133, -0.12665683,  0.13859127,  0.39483023, -0.10526996,\n",
       "        0.46009022, -0.00261852,  0.655059  ,  0.49174708, -0.1929828 ,\n",
       "        1.5695393 , -0.7468905 , -0.07444647,  0.29639   ,  0.08574741,\n",
       "        0.9622282 ,  0.7315965 , -0.14204422, -0.49535516,  1.0943861 ,\n",
       "       -0.05004118, -0.1456839 , -0.8290179 , -0.10814688, -0.13346447,\n",
       "        0.06452737, -0.87385905,  0.0530237 , -0.05195145, -0.48532778,\n",
       "       -0.14783101,  0.4713648 ,  0.11594936,  0.7207866 , -0.00741159,\n",
       "       -0.46860945,  0.35014468,  0.09409344, -0.56500155, -0.19551016,\n",
       "       -0.06186643, -1.4164532 , -0.03668986, -0.03816303,  0.26748544,\n",
       "       -0.03071634,  0.2935313 ,  0.56209016, -0.06893368,  0.92670983,\n",
       "       -0.7101934 ,  0.36958846,  0.01882201,  0.6165253 ,  0.47790796,\n",
       "       -0.28970268,  0.10992491,  0.45790663, -0.05310084,  0.1965636 ,\n",
       "       -0.46964252, -0.11238213, -0.07090787, -0.33326986,  0.5164772 ,\n",
       "        0.00665079, -0.5611254 , -0.35956505, -0.7564858 , -0.09996006,\n",
       "       -0.4039124 , -0.76072687,  0.36532193, -0.8382015 ,  0.1432953 ,\n",
       "       -0.17803475, -0.04781981, -0.7067164 ,  0.42761245, -0.49100482,\n",
       "        0.8179802 , -0.16349928,  0.95724636,  0.05912025, -0.03830861,\n",
       "        0.28085953, -0.29999718,  0.18797033,  0.5205681 , -0.30817878,\n",
       "        0.2164554 , -0.4074065 , -0.6920187 ,  0.15058367,  1.0222269 ,\n",
       "        0.92140335, -0.5421654 , -0.17802121,  0.16732854,  0.09300736,\n",
       "        0.4260004 , -0.29766774, -0.06004657,  0.25474796,  1.3410133 ,\n",
       "       -0.75472856,  0.29130074,  0.45388517,  0.6331787 , -1.2314596 ,\n",
       "       -0.1909565 , -0.9587221 , -0.47813714,  0.58919597, -0.75749665,\n",
       "        0.08179259, -0.76065266,  0.27234855, -0.614315  , -0.3556031 ,\n",
       "       -0.12957239,  0.8588504 ,  0.09444058,  0.19273569, -0.22003968,\n",
       "       -0.39705798,  0.32019997,  0.53308   , -0.2446509 , -0.3078267 ,\n",
       "        0.20321578, -0.01234532,  0.4001887 , -0.2641181 , -0.01992992,\n",
       "       -0.6382765 ,  1.2465271 ,  0.48090062,  0.29398105,  0.16360565,\n",
       "        0.08642233,  1.4503683 , -0.4064758 , -0.5177078 , -0.5807896 ,\n",
       "        0.39227933,  0.18149176, -0.40725642,  1.4002893 ,  0.4935403 ,\n",
       "        0.09004601,  0.26992726, -0.00327307, -0.6080873 ,  0.24891518,\n",
       "       -0.8153352 ,  1.458048  ,  0.16038811, -0.8473992 ,  1.0560719 ,\n",
       "        0.61619675,  0.12927909,  0.45915022, -0.15630719, -0.35337418,\n",
       "        0.34523028,  0.10507457,  0.47989774, -0.33938172,  0.11564808,\n",
       "       -0.05912752,  0.38900515,  0.99625266,  1.3365225 ,  0.40721062,\n",
       "        0.01941132,  0.3587792 ,  0.0552961 ,  0.35594186,  0.35127613,\n",
       "        0.89822584, -0.05622411, -0.8698183 ,  0.89963335, -0.13031314,\n",
       "       -0.23362322, -0.55683476, -0.02610582, -1.1963712 , -1.0731283 ,\n",
       "       -0.6911505 , -0.74077475,  0.21804535,  0.00281326, -0.869587  ,\n",
       "        1.182368  , -0.8261802 , -0.4715313 ,  0.4702758 ,  0.02809855,\n",
       "       -0.562915  ,  0.01828133, -0.09765989, -0.5477444 , -0.59357476,\n",
       "        0.3095902 , -0.15323204, -0.6107486 ,  0.49841893,  0.4684249 ,\n",
       "        0.13437885, -0.12025867,  0.33705214,  0.58734363,  0.15504402,\n",
       "       -0.23401287,  0.8156877 , -1.0401262 , -0.54051054,  0.16663441,\n",
       "        0.80172575, -0.53975725,  0.87772226,  0.09531943,  1.4932169 ,\n",
       "        0.30889687,  0.5160619 ,  0.23550622, -0.2669634 , -0.00813173,\n",
       "       -0.21560791,  0.70376194,  0.14972246, -0.03046258,  0.6755232 ,\n",
       "        0.20451963, -0.9983631 ,  0.5903063 ,  0.5102438 ,  0.63334584,\n",
       "        0.5889807 , -0.7600264 , -0.19019353, -1.1063337 , -0.1172516 ,\n",
       "        0.7740473 ,  0.295998  ,  1.3826475 ,  0.06323612,  0.13727193],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['the']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
