{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2018-05-14 19:58:09 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 6.3.1\n",
      "\n",
      "numpy 1.14.3\n",
      "pandas 0.22.0\n",
      "sklearn 0.19.1\n",
      "matplotlib 2.2.2\n"
     ]
    }
   ],
   "source": [
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# change default style figure and font size\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,sklearn,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingyuliu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet\n",
    "from spotlight.evaluation import sequence_mrr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Interactions dataset (944 users x 1683 items x 100000 interactions)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length = 200\n",
    "min_sequence_length = 20\n",
    "step_size = 200\n",
    "random_state = np.random.RandomState(100)\n",
    "\n",
    "dataset = get_movielens_dataset('100K')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = (os.environ.get('CUDA') is not None or\n",
    "        shutil.which('nvidia-smi') is not None)\n",
    "\n",
    "NUM_SAMPLES = 1\n",
    "\n",
    "LEARNING_RATES = [1e-3, 1e-2, 5 * 1e-2, 1e-1]\n",
    "LOSSES = ['adaptive_hinge']  # ['bpr', 'hinge', 'adaptive_hinge', 'pointwise']\n",
    "BATCH_SIZE = [8, 16, 32, 256]\n",
    "EMBEDDING_DIM = [8, 16, 32, 64, 128, 256]\n",
    "N_ITER = list(range(5, 20))\n",
    "L2 = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_lstm_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "    for params in sampler:\n",
    "        yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation='lstm',\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return model, test_mrr, val_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, rest = user_based_train_test_split(dataset, test_percentage = 0.2,\n",
    "                                          random_state=random_state)\n",
    "test, validation = user_based_train_test_split(rest,\n",
    "                                               test_percentage=0.5,\n",
    "                                               random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingyuliu/anaconda3/lib/python3.6/site-packages/torch/tensor.py:255: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "/Users/mingyuliu/anaconda3/lib/python3.6/site-packages/spotlight/factorization/implicit.py:244: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  epoch_loss += loss.data[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MRR 0.031805849817807076 val MRR 0.035169679226644525\n"
     ]
    }
   ],
   "source": [
    "from spotlight.evaluation import mrr_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "\n",
    "model = ImplicitFactorizationModel(n_iter=7,\n",
    "                                   loss='adaptive_hinge')\n",
    "model.fit(train)\n",
    "\n",
    "val_mrr = mrr_score(model, validation)\n",
    "test_mrr = mrr_score(model, test)\n",
    "print('Test MRR {} val MRR {}'.format(\n",
    "        test_mrr.mean(), val_mrr.mean()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequence interactions dataset (855 sequences x 200 sequence length)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq = train.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                          min_sequence_length=min_sequence_length,\n",
    "                          step_size=step_size)\n",
    "test_seq = test.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                        min_sequence_length=min_sequence_length,\n",
    "                        step_size=step_size)\n",
    "validation_seq = validation.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                                    min_sequence_length=min_sequence_length,\n",
    "                                    step_size=step_size)\n",
    "train_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating {'n_iter': 19, 'loss': 'adaptive_hinge', 'learning_rate': 0.1, 'l2': 1e-05, 'embedding_dim': 128, 'batch_size': 256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingyuliu/anaconda3/lib/python3.6/site-packages/spotlight/sequence/implicit.py:253: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  epoch_loss += loss.data[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 1.2338563203811646\n",
      "Epoch 1: loss 1.0411996841430664\n",
      "Epoch 2: loss 1.0209192037582397\n",
      "Epoch 3: loss 0.9970923662185669\n",
      "Epoch 4: loss 0.9197668433189392\n",
      "Epoch 5: loss 0.8312190175056458\n",
      "Epoch 6: loss 0.782036542892456\n",
      "Epoch 7: loss 0.7287655472755432\n",
      "Epoch 8: loss 0.6983942985534668\n",
      "Epoch 9: loss 0.6871305108070374\n",
      "Epoch 10: loss 0.6732932329177856\n",
      "Epoch 11: loss 0.649735689163208\n",
      "Epoch 12: loss 0.6486098766326904\n",
      "Epoch 13: loss 0.640937328338623\n",
      "Epoch 14: loss 0.621277391910553\n",
      "Epoch 15: loss 0.61250239610672\n",
      "Epoch 16: loss 0.6008219122886658\n",
      "Epoch 17: loss 0.6032966375350952\n",
      "Epoch 18: loss 0.5985197424888611\n",
      "Test MRR 0.04692862489922453 val MRR 0.054846583599892015\n"
     ]
    }
   ],
   "source": [
    "eval_fnc, sample_fnc = (evaluate_lstm_model,\n",
    "                        sample_lstm_hyperparameters)\n",
    "\n",
    "for hyperparameters in sample_fnc(random_state, NUM_SAMPLES):\n",
    "    print('Evaluating {}'.format(hyperparameters))\n",
    "\n",
    "    (model, test_mrr, val_mrr) = eval_fnc(hyperparameters,\n",
    "                                   train_seq,\n",
    "                                   test_seq,\n",
    "                                   validation_seq,\n",
    "                                   random_state)\n",
    "\n",
    "    print('Test MRR {} val MRR {}'.format(\n",
    "        test_mrr.mean(), val_mrr.mean()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences shape: (127, 199)\n",
      "targets shape: (127,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "sequences = test_seq.sequences[:, :-1]\n",
    "targets = test_seq.sequences[:, -1]\n",
    "print('sequences shape:', sequences.shape)\n",
    "print('targets shape:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057476799713576686"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence_mrr_score\n",
    "FLOAT_MAX = np.finfo(np.float32).max\n",
    "\n",
    "mrrs = []\n",
    "for i in range(sequences.shape[0]):\n",
    "    # negate the score to sort in decreasing order later\n",
    "    predictions = -model.predict(sequences[i])\n",
    "    # exclude seqeuences that already occurred\n",
    "    predictions[sequences[i]] = FLOAT_MAX\n",
    "    mrr = (1.0 / rankdata(predictions))[targets[i]]\n",
    "    mrrs.append(mrr)\n",
    "\n",
    "mrrs = np.array(mrrs)\n",
    "mrrs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(user_ids, item_ids, indices, max_sequence_len, step_size):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns user_id along with the corresponding item_ids\n",
    "    \"\"\"\n",
    "    for i in range(len(indices)):\n",
    "        start = indices[i]\n",
    "        if i >= len(indices) - 1:\n",
    "            stop = None\n",
    "        else:\n",
    "            stop = indices[i + 1]\n",
    "        \n",
    "        tensor = item_ids[start:stop]\n",
    "        for seq in sliding_window(tensor, max_sequence_len, step_size):\n",
    "            yield user_ids[i], seq\n",
    "        \n",
    "def sliding_window(tensor, window_size, step_size):\n",
    "    for i in range(len(tensor), 0, -step_size):\n",
    "        yield tensor[max(i - window_size, 0):i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877, 200)\n",
      "(855, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[214, 182,  48, ...,   5,  74, 102],\n",
       "       [  0,   0,   0, ...,  26,  89,   8],\n",
       "       [  0,   0,   0, ..., 320, 317, 181],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 879, 355, 316],\n",
       "       [  0,   0,   0, ...,  95,  31, 662],\n",
       "       [  0,   0,   0, ..., 230, 228, 234]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size = max_sequence_length\n",
    "\n",
    "# sort first by user id, then by timestamp\n",
    "sort_indices = np.lexsort((train.timestamps, train.user_ids))\n",
    "user_ids = train.user_ids[sort_indices]\n",
    "item_ids = train.item_ids[sort_indices]\n",
    "user_ids, indices, counts = np.unique(user_ids, return_index = True, return_counts = True)\n",
    "\n",
    "num_subsequences = int(np.ceil(counts / step_size).sum())\n",
    "sequences = np.zeros((num_subsequences, max_sequence_length), dtype = np.int)\n",
    "sequence_users = np.empty(num_subsequences, dtype = np.int)\n",
    "\n",
    "generated_seq = generate_sequence(\n",
    "    user_ids, item_ids, indices, max_sequence_length, step_size)\n",
    "for i, (user_id, seq) in enumerate(generated_seq):\n",
    "    # perform pre-zero-padding while assigning the sub-sequences\n",
    "    sequences[i, -len(seq):] = seq\n",
    "    sequence_users[i] = user_id\n",
    "\n",
    "print(sequences.shape)\n",
    "if min_sequence_length is not None:\n",
    "    long_enough = sequences[:, -min_sequence_length] != 0\n",
    "    sequences = sequences[long_enough]\n",
    "    sequence_users = sequence_users[long_enough]\n",
    "\n",
    "print(sequences.shape)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default initialization methods for layers is determined by the reset_parameters method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from spotlight.layers import ScaledEmbedding, ZeroEmbedding\n",
    "\n",
    "PADDING_IDX = 0\n",
    "\n",
    "def shuffle(array, random_state = 1234):\n",
    "    rstate = np.random.RandomState(random_state)\n",
    "    shuffle_indices = np.arange(array.shape[0])\n",
    "    rstate.shuffle(shuffle_indices)\n",
    "    return array[shuffle_indices]\n",
    "\n",
    "def minibatch(array, batch_size = 128):\n",
    "    for i in range(0, len(array), batch_size):\n",
    "        yield array[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,   286,   878,   288,   322,\n",
       "           324,   258,   268,   327,   289,   245,   294,   302,   180,\n",
       "            56,   483,   195,   474,   187,   191,   127,   179,   523,\n",
       "          1500,    97,   215,   318,    69,   100,   223,   205,   204,\n",
       "           174,   134,   210,   181,   232,   403,    87,    50,   172,\n",
       "            64,   135],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           288,   319,   872,   682,   260,   294,   748,   873,   988,\n",
       "           888,   948,   276,   255,   220,   237,  1152,   282,     1,\n",
       "          1315,   111,  1014,   845,   756,   595,   274,  1278,   284,\n",
       "           846,   866,   280,   535,  1095,   763,   975,  1048,  1277,\n",
       "          1357,   471,   120,   934,   928,   815,   508,   476,   278,\n",
       "           245,   546]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sequence interactions\n",
    "# train.num_items, sequences, sequence_users\n",
    "num_items = train.num_items\n",
    "\n",
    "# 1. shuffle\n",
    "seqs = shuffle(sequences)\n",
    "\n",
    "# 2. convert to gpu if cuda is available\n",
    "sequence_tensor = torch.from_numpy(seqs)\n",
    "\n",
    "# 3. generate mini-batches, size of [batch size, max_sequence_length]\n",
    "sequence_batch = next(minibatch(sequence_tensor, batch_size = 2))\n",
    "sequence_var = Variable(sequence_batch)\n",
    "sequence_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the behavior of padding in torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 5, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, 2, 4)\n",
    "F.pad(inputs.unsqueeze(3), (0, 0, 1, 0)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8845, -1.1054,  0.1424, -0.3206],\n",
       "         [ 0.1817,  0.5613, -0.8864, -0.2151],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, 2, 4)\n",
    "F.pad(inputs, (0, 0, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 201, 32])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0169,  0.0165,  0.0149,  ..., -0.0250, -0.0165, -0.0360],\n",
      "         [ 0.0460, -0.0251, -0.0332,  ...,  0.0203,  0.0172,  0.0537],\n",
      "         [ 0.0307,  0.0455,  0.0651,  ...,  0.0521,  0.0297,  0.0208]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0185,  0.0262, -0.0536,  ...,  0.0372,  0.0189, -0.0139],\n",
      "         [ 0.0255,  0.0020,  0.0259,  ...,  0.0111,  0.0833, -0.0163],\n",
      "         [ 0.0585,  0.0156, -0.0272,  ..., -0.0076, -0.0270,  0.0429]]])\n"
     ]
    }
   ],
   "source": [
    "from representations import LSTMNet\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "net = LSTMNet(num_items)\n",
    "\n",
    "# perform padding with zeros from the left on the\n",
    "# [max_sequence_length] dimension\n",
    "sequence_embeddings1 = net.item_embedding(sequence_var)\n",
    "sequence_embeddings1 = F.pad(sequence_embeddings1, (0, 0, 1, 0))\n",
    "print(sequence_embeddings1.size())\n",
    "print(sequence_embeddings1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 200])\n",
      "torch.Size([2, 201, 32])\n",
      "torch.Size([2, 32, 201])\n"
     ]
    }
   ],
   "source": [
    "# make embedding dimension the channel, i.e.\n",
    "# size of [batch_size, embedding_dim, max_sequence_length]\n",
    "sequence_embeddings = net.item_embedding(sequence_var).permute(0, 2, 1)\n",
    "print(sequence_embeddings.size())\n",
    "\n",
    "# add a trailing dimension of 1 to perform\n",
    "# padding with zeros from the left on the\n",
    "# max_sequence_length dimension; then remove the\n",
    "# training dimension once we're done\n",
    "sequence_embeddings = sequence_embeddings.unsqueeze(3)\n",
    "sequence_embeddings = F.pad(sequence_embeddings, (0, 0, 1, 0)).squeeze(3)\n",
    "sequence_embeddings = sequence_embeddings.permute(0, 2, 1)\n",
    "print(sequence_embeddings.size())\n",
    "\n",
    "user_representations, _ = net.lstm(sequence_embeddings)\n",
    "user_representations = user_representations.permute(0, 2, 1)\n",
    "print(user_representations.size())\n",
    "\n",
    "# user_representations[:, :, :-1], user_representations[:, :, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embedding = net.item_embedding(sequence_var).permute(0, 2, 1)\n",
    "target_bias = net.item_biases(sequence_var).squeeze()\n",
    "dot = (user_representations[:, :, :-1] * target_embedding).sum(dim = 1)\n",
    "output = dot + target_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??  SESSION-PARALLEL MINI-BATCHES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "234px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
