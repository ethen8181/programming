{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from recommender import BIKNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "from itertools import combinations\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIKNN on Small Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>placeID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  placeID  rating\n",
       "0       1       32       2\n",
       "1       1       33       1\n",
       "2       1       76       2\n",
       "3       1       82       1\n",
       "4       1       86       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ratings = pd.read_csv('data/final_rating.csv')\n",
    "final_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>placeID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>109</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>90</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID  placeID  rating\n",
       "901     109       79       2\n",
       "72        8       41       1\n",
       "728      90      107       2\n",
       "327      39       16       1\n",
       "131      15       49       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train and X_test is your training and testing data\n",
    "X_train, X_test = train_test_split( \n",
    "    final_ratings, \n",
    "    test_size = 0.2, \n",
    "    stratify = final_ratings['userID'].values,\n",
    "    random_state = 1234 # this is the seed for reproducible train/test split\n",
    ")\n",
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the full dataset\n",
    "# column order: user id, item id and ratings\n",
    "train = pd.read_csv( 'data/u1.base', sep = '\\t', header = None )\n",
    "train = train.iloc[ :, 0:3 ]\n",
    "test  = pd.read_csv( 'data/u1.test', sep = '\\t', header = None )\n",
    "test  = test.iloc[ :, 0:3 ]\n",
    "column_names = [ 'user_ids', 'item_ids', 'ratings' ]\n",
    "train.columns = column_names\n",
    "test.columns  = column_names\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only retain users that are frequently rating \n",
    "# change the quantile for percentage that are retained\n",
    "histogram_counts = train['user_ids'].value_counts()\n",
    "df_value_counts  = pd.DataFrame( histogram_counts > histogram_counts.quantile(0.5) )\n",
    "df_value_counts  = df_value_counts.reset_index()\n",
    "frequent_users   = df_value_counts.loc[ df_value_counts['user_ids'], 'index' ]\n",
    "\n",
    "train = train[ train['user_ids'].isin(frequent_users) ]\n",
    "test  = test[ test['user_ids'].isin(frequent_users) ]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "K = 20 \n",
    "B1 = 25\n",
    "B2 = 25\n",
    "\n",
    "# X_train.columns = [ 'user_ids', 'item_ids', 'ratings' ]\n",
    "# data = X_train.copy()\n",
    "\n",
    "data = train.copy()\n",
    "user_ids = np.array(data['user_ids'])\n",
    "item_ids = np.array(data['item_ids'])\n",
    "ratings  = np.array(data['ratings'])\n",
    "\n",
    "unique_item_ids = np.unique(item_ids)\n",
    "unique_user_ids = np.unique(user_ids)\n",
    "item_ids_dict = { v: k for k, v in enumerate(unique_item_ids) }\n",
    "size = len(item_ids_dict)\n",
    "F   = np.ones( ( size, size ) )\n",
    "G   = np.ones( ( size, size ) )\n",
    "sup = np.ones( ( size, size ), dtype = np.int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _calculate_similarity( item1, item2 ):\n",
    "    \"\"\"\n",
    "    item1 = 1\n",
    "    item2 = 7\n",
    "    support, numerator, denominator = _calculate_similarity( item1, item2 )\n",
    "    \"\"\"\n",
    "    item1_boolean = item_ids == item1\n",
    "    item2_boolean = item_ids == item2\n",
    "    item1_users   = user_ids[item1_boolean]\n",
    "    item2_users   = user_ids[item2_boolean]\n",
    "    common_users  = list( set(item1_users).intersection(item2_users) )\n",
    "\n",
    "    if not common_users:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    match = np.in1d( user_ids, common_users )\n",
    "    item1_ratings = ratings[item1_boolean & match]\n",
    "    item2_ratings = ratings[item2_boolean & match]\n",
    "    \n",
    "    support = len(common_users)\n",
    "    numerator = item1_ratings.dot(item2_ratings)\n",
    "    denominator = np.sum( item1_ratings ** 2 ) + np.sum( item2_ratings ** 2 )    \n",
    "    return support, numerator, denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# around 7 minutes\n",
    "supports = []\n",
    "for item1, item2 in combinations( unique_item_ids, 2 ):\n",
    "    i1, i2 = item_ids_dict[item1], item_ids_dict[item2]\n",
    "    support, numerator, denominator = _calculate_similarity( item1, item2 )\n",
    "    F[i1][i2] = F[i2][i1] = numerator\n",
    "    G[i1][i2] = G[i2][i1] = denominator\n",
    "    sup[i1][i2] = sup[i2][i1] = support\n",
    "    supports.append(support)\n",
    "\n",
    "supports = np.array(supports)\n",
    "N = supports.shape[0]\n",
    "mean = np.mean(supports)\n",
    "variance = np.var(supports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std = np.sqrt(variance)\n",
    "\n",
    "w = np.ones( [ size, size ] )\n",
    "for i1, i2 in combinations( item_ids_dict.values(), 2 ):\n",
    "    weight = norm.cdf( sup[i1][i2], mean, std )\n",
    "    w[i1][i2] = w[i2][i1] = weight\n",
    "    \n",
    "sim_w = ( F / G ) * w\n",
    "sim_w[ np.isnan(sim_w) ] = 0 # there're nan values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_avg = np.mean(ratings)\n",
    "known_ratings_count = ratings.shape[0]\n",
    "\n",
    "# every items' / users' bias\n",
    "user_ratings_sum = {}\n",
    "item_ratings_sum = {}\n",
    "user_ratings_count = {} \n",
    "item_ratings_count = {}\n",
    "\n",
    "for item_id in unique_item_ids:\n",
    "    item_ratings = ratings[ item_ids == item_id ]\n",
    "    item_ratings_sum[item_id] = np.sum(item_ratings)\n",
    "    item_ratings_count[item_id] = item_ratings.shape[0]\n",
    "    \n",
    "for user_id in unique_user_ids:\n",
    "    user_ratings = ratings[ user_ids == user_id ]\n",
    "    user_ratings_sum[user_id] = np.sum(user_ratings)\n",
    "    user_ratings_count[user_id] = user_ratings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _calculate_item_bias( item_id ):\n",
    "    # _n, _d stands for numerator and denominator\n",
    "    item_bias_n = item_ratings_sum[item_id] - global_avg * item_ratings_count[item_id]\n",
    "    item_bias_d = B1 + item_ratings_count[item_id]\n",
    "    item_bias = item_bias_n / item_bias_d\n",
    "    return item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _calculate_user_bias( user_id, user_rated_item_id ):\n",
    "\n",
    "    item_bias_total = 0\n",
    "    for other_item_id in user_rated_item_id:\n",
    "        item_bias_total += _calculate_item_bias(other_item_id)\n",
    "\n",
    "    user_bias_n = ( user_ratings_sum[user_id] - \n",
    "                    global_avg * user_ratings_count[user_id] - \n",
    "                    item_bias_total )\n",
    "    user_bias_d = B2 + user_ratings_count[user_id]\n",
    "    user_bias = user_bias_n / user_bias_d\n",
    "    return user_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _predict_rating( user_id, item_id, user, user_item_ids  ):\n",
    "    \"\"\"_predict_rating( user_id = 1, item_id = 1 )\"\"\"\n",
    "    item_bias = _calculate_item_bias(item_id)\n",
    "    user_bias = _calculate_user_bias( user_id, user_rated_item_id )\n",
    "    baseline  = global_avg + item_bias + user_bias\n",
    "    \n",
    "    similars = []\n",
    "    other_item_ids = set(user_rated_item_id).difference( set([item_id]) )\n",
    "    for other_item_id in other_item_ids:\n",
    "        similarity = sim_w[ item_ids_dict[item_id] ][ item_ids_dict[other_item_id] ]\n",
    "        similars.append( ( other_item_id, similarity ) )\n",
    "\n",
    "    knearest = heapq.nlargest( K, similars, key = itemgetter(1) )\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for nearest_id, sim in knearest:\n",
    "        nearest_rating = ratings[ ( item_ids == nearest_id) & user ][0]\n",
    "        nearest_item_bias = _calculate_item_bias(nearest_id)\n",
    "        numerator += sim * ( nearest_rating - global_avg - user_bias - nearest_item_bias )\n",
    "        denominator += sim\n",
    "\n",
    "    try:\n",
    "        rating = baseline + ( numerator / denominator )\n",
    "    except ZeroDivisionError:\n",
    "        rating = baseline\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change column access values\n",
    "test.column = [ 'user_ids', 'item_ids', 'ratings' ]\n",
    "new_data = test.iloc[:30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for idx1, ( user_id, item_id1, rating1 ) in enumerate(new_data):\n",
    "    \n",
    "    # obtain all the other items and ratings associated with the user\n",
    "    user = user_ids == user_id\n",
    "    user_item_ids = item_ids[user]\n",
    "    user_ratings = ratings[user]\n",
    "    \n",
    "    predicted = _predict_rating( user_id, item_id1, user, user_item_ids )\n",
    "    prediction.append(predicted)\n",
    "    \n",
    "    # update a bunch of stuff according to all the \n",
    "    # other items and ratings associated with the user\n",
    "    update( user_item_ids, user_ratings )\n",
    "    \n",
    "    # if index1 % iterations == 0:\n",
    "    #    _update_support_weight_and_similarity()\n",
    "    \n",
    "    global_avg_new_n = global_avg * known_ratings_count + rating\n",
    "    known_ratings_count += 1\n",
    "    global_avg_new_d = known_ratings_count\n",
    "    global_avg  = global_avg_new_n / global_avg_new_d\n",
    "\n",
    "    user_ratings_sum[user_id] += rating\n",
    "    item_ratings_sum[item_id] += rating\n",
    "    user_ratings_count[user_id] += 1\n",
    "    item_ratings_count[item_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update( user_item_ids, user_ratings ):\n",
    "    global mean\n",
    "    global variance\n",
    "    for item_id2, rating2 in zip( user_item_ids, user_ratings ):\n",
    "        i1 = item_ids_dict[item_id1]\n",
    "        i2 = item_ids_dict[item_id2]\n",
    "\n",
    "        F_new = F[i1][i2] + ( rating1 * rating2 )\n",
    "        G_new = G[i1][i2] + ( rating1 ** 2 + rating2 ** 2 )\n",
    "        F[i1][i2] = F[i2][i1] = F_new\n",
    "        G[i1][i2] = G[i2][i1] = G_new    \n",
    "        \n",
    "        # compute and update the new support's mean, variance and count\n",
    "        sup_old = sup[i1][i2]\n",
    "        sup_delta = 1\n",
    "        sup_new = sup_old + sup_delta       \n",
    "        mean_new = mean + sup_delta / N\n",
    "        variance_new = ( variance + \n",
    "                         ( 2 * sup_delta * sup_old + sup_delta ** 2 ) / N +\n",
    "                         mean ** 2 - mean_new ** 2 )\n",
    "\n",
    "        mean = mean_new\n",
    "        variance = variance_new\n",
    "        sup[i1][i2] = sup[i2][i1] = sup_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-6a5a810a9e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this runs a single BIKNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbiknn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBIKNN\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbiknn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m'user_ids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item_ids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ratings'\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbiknn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ethen/programming/recommendation/BIKNN/recommender/biknn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, column_names)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_item_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_ids_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_ids_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_similarity\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mitem1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ethen/programming/recommendation/BIKNN/recommender/biknn.py\u001b[0m in \u001b[0;36m_calculate_similarity\u001b[0;34m(self, item1, item2)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# given the set of common users that rated the item,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# find their ratings for both item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_users\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mitem1_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem1_boolean\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mitem2_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem2_boolean\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ethen/anaconda/lib/python3.5/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# this runs a single BIKNN\n",
    "biknn1 = BIKNN( K = 20, B1 = 25, B2 = 25, iterations = 100000 )\n",
    "biknn1.fit( data = train, column_names = [ 'user_ids', 'item_ids', 'ratings' ] )\n",
    "pred = biknn1.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore this code chunk\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "data = pd.read_csv( 'test_data.txt', sep = ',', header = None )\n",
    "data.head(4)\n",
    "dict1 = { \n",
    "    'user_id': [6, 5],\n",
    "    'item_id': [1, 2],\n",
    "    'ratings': [5, 2]\n",
    "}\n",
    "test1 = pd.DataFrame( dict1, columns = [ 'user_id', 'item_id', 'ratings' ] )\n",
    "test1\n",
    "\"\"\"\n",
    "print('ignore this code chunk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
