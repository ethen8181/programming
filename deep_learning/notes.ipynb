{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c865ffbe",
   "metadata": {},
   "source": [
    "Self supervision methods have gained popularity.\n",
    "\n",
    "Roberta primary modifications:\n",
    "\n",
    "- Train the model longer, with bigger batches over more data. They collected an additional CC-NEWS dataset\n",
    "- Remove the next sentence prediction from the objective function. Keeping only the masked language model pretraining.\n",
    "- Dynamically changing the masking pattern applied to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ec931",
   "metadata": {},
   "source": [
    "## Gradient Accumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa237cad",
   "metadata": {},
   "source": [
    "- https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/02/19/gradient-accumulation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e2d97d",
   "metadata": {},
   "source": [
    "## Mixed Precision Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c67c211",
   "metadata": {},
   "source": [
    "Efficient training of large neural network relies on the use of lower precision data types. e.g. float16 are only half of size of float32 and can reduce memory required for training our models, allowing for larger inputs/batches, which translates to training speed benefits while preserving model convergence/performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606e0b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 18 18:07:34 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:1A:00.0 Off |                    0 |\r\n",
      "| N/A   60C    P0   267W / 300W |  21414MiB / 32510MiB |     98%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db08fe3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
