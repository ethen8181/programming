{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Indexing-TMDB-Movies\" data-toc-modified-id=\"Indexing-TMDB-Movies-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Indexing TMDB Movies</a></span></li><li><span><a href=\"#Basic-Searching\" data-toc-modified-id=\"Basic-Searching-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Basic Searching</a></span></li><li><span><a href=\"#Query-Validation-API\" data-toc-modified-id=\"Query-Validation-API-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Query Validation API</a></span></li><li><span><a href=\"#Debugging-Analysis\" data-toc-modified-id=\"Debugging-Analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Debugging Analysis</a></span></li><li><span><a href=\"#Solving-The-Matching-Problem\" data-toc-modified-id=\"Solving-The-Matching-Problem-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Solving The Matching Problem</a></span></li><li><span><a href=\"#Repeat-the-search\" data-toc-modified-id=\"Repeat-the-search-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Repeat the search</a></span></li><li><span><a href=\"#Decomposing-Relevance-Score-With-Lucene’s-Explain\" data-toc-modified-id=\"Decomposing-Relevance-Score-With-Lucene’s-Explain-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Decomposing Relevance Score With Lucene’s Explain</a></span></li><li><span><a href=\"#Fixing-Space-Jam-vs-Alien-Ranking\" data-toc-modified-id=\"Fixing-Space-Jam-vs-Alien-Ranking-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Fixing Space Jam vs Alien Ranking</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing TMDB Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poster_path': '/mfMndRWFbzXbTx0g3rHUXFAxyOh.jpg',\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'revenue': 0,\n",
       " 'overview': 'When the FBI hires her to go undercover at a college sorority, Molly Morris (Miley Cyrus) must transform herself from a tough, streetwise private investigator to a refined, sophisticated university girl to help protect the daughter of a one-time Mobster. With several suspects on her list, Molly unexpectedly discovers that not everyone is who they appear to be, including herself.',\n",
       " 'video': False,\n",
       " 'id': 93837,\n",
       " 'genres': [{'id': 28, 'name': 'Action'}, {'id': 35, 'name': 'Comedy'}],\n",
       " 'title': 'So Undercover',\n",
       " 'tagline': \"Meet the FBI's new secret weapon\",\n",
       " 'vote_count': 55,\n",
       " 'homepage': '',\n",
       " 'belongs_to_collection': None,\n",
       " 'original_language': 'en',\n",
       " 'status': 'Released',\n",
       " 'spoken_languages': [{'iso_639_1': 'en', 'name': 'English'}],\n",
       " 'imdb_id': 'tt1766094',\n",
       " 'adult': False,\n",
       " 'backdrop_path': '/o4Tt60z94Hbgk8adeZG9WE4S2im.jpg',\n",
       " 'production_companies': [{'name': 'Exclusive Media Group', 'id': 11448}],\n",
       " 'release_date': '2012-01-01',\n",
       " 'popularity': 0.345124796829192,\n",
       " 'original_title': 'So Undercover',\n",
       " 'budget': 0,\n",
       " 'cast': [{'name': 'Miley Cyrus',\n",
       "   'character': 'Molly',\n",
       "   'id': 76594,\n",
       "   'credit_id': '52fe49419251416c750c21c9',\n",
       "   'cast_id': 10,\n",
       "   'profile_path': '/4cWl6nJTQMexqZFFDfaJucwhqGY.jpg',\n",
       "   'order': 0},\n",
       "  {'name': 'Joshua Bowman',\n",
       "   'character': 'Nicholas',\n",
       "   'id': 139835,\n",
       "   'credit_id': '52fe49419251416c750c21cd',\n",
       "   'cast_id': 11,\n",
       "   'profile_path': '/FOSRcKOJqCZzpFhBCzlEphp5F.jpg',\n",
       "   'order': 1},\n",
       "  {'name': 'Eloise Mumford',\n",
       "   'character': 'Sasha',\n",
       "   'id': 222130,\n",
       "   'credit_id': '52fe49419251416c750c21d1',\n",
       "   'cast_id': 12,\n",
       "   'profile_path': '/6yT9OjHcnG55iGjq7XFvd2qpYT2.jpg',\n",
       "   'order': 2},\n",
       "  {'name': 'Jeremy Piven',\n",
       "   'character': 'Armon',\n",
       "   'id': 12799,\n",
       "   'credit_id': '52fe49419251416c750c21d5',\n",
       "   'cast_id': 13,\n",
       "   'profile_path': '/qtho4ZUcValnVvscTGgyWfUr4VP.jpg',\n",
       "   'order': 3},\n",
       "  {'name': 'Autumn Reeser',\n",
       "   'character': 'Bizzy',\n",
       "   'id': 74607,\n",
       "   'credit_id': '52fe49419251416c750c21d9',\n",
       "   'cast_id': 14,\n",
       "   'profile_path': '/vZlZQkQzQ0PSCnQT77vqEFnYsoO.jpg',\n",
       "   'order': 4},\n",
       "  {'name': 'Alexis Knapp',\n",
       "   'character': 'Taylor',\n",
       "   'id': 999790,\n",
       "   'credit_id': '52fe49419251416c750c21dd',\n",
       "   'cast_id': 15,\n",
       "   'profile_path': '/jhQeoRHhCig8dtJxthKChQmAERQ.jpg',\n",
       "   'order': 5},\n",
       "  {'name': 'Matthew Settle',\n",
       "   'character': 'Professor Talloway',\n",
       "   'id': 33286,\n",
       "   'credit_id': '52fe49419251416c750c21e1',\n",
       "   'cast_id': 16,\n",
       "   'profile_path': '/neODd3vTVEb7TXOWEZC44ZZu1yk.jpg',\n",
       "   'order': 6},\n",
       "  {'name': 'Megan Park',\n",
       "   'character': 'Cotton',\n",
       "   'id': 55615,\n",
       "   'credit_id': '52fe49419251416c750c21e5',\n",
       "   'cast_id': 17,\n",
       "   'profile_path': '/AjIaQKbjMgYcJxalCBM4MGREss0.jpg',\n",
       "   'order': 7},\n",
       "  {'name': \"Mike O'Malley\",\n",
       "   'character': 'Sam',\n",
       "   'id': 87192,\n",
       "   'credit_id': '52fe49419251416c750c21e9',\n",
       "   'cast_id': 18,\n",
       "   'profile_path': '/9VwiKnQySJN7buvCg53v4NB5Tj7.jpg',\n",
       "   'order': 8},\n",
       "  {'name': 'Kelly Osbourne',\n",
       "   'character': 'Becky',\n",
       "   'id': 178425,\n",
       "   'credit_id': '52fe49419251416c750c21ed',\n",
       "   'cast_id': 19,\n",
       "   'profile_path': '/ub2UobCm9Fe4PYWgerPQkdXMSQA.jpg',\n",
       "   'order': 9},\n",
       "  {'name': 'Lauren McKnight',\n",
       "   'character': 'Alex',\n",
       "   'id': 560298,\n",
       "   'credit_id': '52fe49419251416c750c21f1',\n",
       "   'cast_id': 20,\n",
       "   'profile_path': None,\n",
       "   'order': 10}],\n",
       " 'directors': [{'name': 'Tom Vaughan',\n",
       "   'department': 'Directing',\n",
       "   'job': 'Director',\n",
       "   'credit_id': '52fe49419251416c750c2195',\n",
       "   'profile_path': '/opDMR3lConDBNSiVmqt4h6TMFBF.jpg',\n",
       "   'id': 56717}],\n",
       " 'vote_average': 5.9,\n",
       " 'runtime': 94}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "def extract():\n",
    "    with open('tmdb.json') as f:\n",
    "        return json.loads(f.read())\n",
    "    \n",
    "\n",
    "movies = extract()\n",
    "\n",
    "# we can check some sample movie id, to check a sense of what\n",
    "# the data looks like\n",
    "# movie_ids = ['93837', '8193', '8195', '5', '8202', '11']\n",
    "movies['93837']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.delete('http://localhost:9200/tmdb')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an index\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html\n",
    "settings = {\n",
    "    'settings': {\n",
    "        'index': {\n",
    "            'number_of_shards': 1,\n",
    "            'number_of_replicas': 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.put('http://localhost:9200/tmdb', data=json.dumps(settings), headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "curl -X PUT \"localhost:9200/tmdb\" -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "    \"settings\" : {\n",
    "        \"index\" : {\n",
    "            \"number_of_shards\" : 1, \n",
    "            \"number_of_replicas\" : 1 \n",
    "        }\n",
    "    }\n",
    "}\n",
    "'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing API\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html\n",
    "# https://www.elastic.co/guide/en/elasticsearch/guide/master/index-doc.html\n",
    "\n",
    "bulk_index_cmd = ''\n",
    "for movie_id, movie in movies.items():\n",
    "    # a document is uniquely identified by the index, the type and id\n",
    "    # it's worth noting that there's a note on removing the capabilities of\n",
    "    # having multiple types under one index, and going forward the type will\n",
    "    # just to set to '_doc'\n",
    "    # https://www.elastic.co/guide/en/elasticsearch/reference/current/removal-of-types.html\n",
    "    index_cmd = {\n",
    "        'index': {\n",
    "            '_index': 'tmdb',\n",
    "            '_type': '_doc',\n",
    "            '_id': movie_id\n",
    "        }\n",
    "    }\n",
    "    bulk_index_cmd += (json.dumps(index_cmd) + '\\n' + json.dumps(movie) + '\\n')\n",
    "\n",
    "    \n",
    "response = requests.post('http://localhost:9200/_bulk', data=bulk_index_cmd, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex(movies, mapping_settings=None):\n",
    "    \"\"\"Create the tmdb index, and movie type. We can interact with it using tmdb/movie\"\"\"\n",
    "    response = requests.delete('http://localhost:9200/tmdb')\n",
    "\n",
    "    settings = {\n",
    "        'settings': {\n",
    "            'index': {\n",
    "                'number_of_shards': 1,  # for reproducibility, document frequency is stored per shard\n",
    "                'number_of_replicas': 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if mapping_settings is not None:\n",
    "        settings.update(mapping_settings)\n",
    "    \n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.put('http://localhost:9200/tmdb',\n",
    "                            data=json.dumps(settings), headers=headers)\n",
    "\n",
    "    bulk_index_cmd = ''\n",
    "    for movie_id, movie in movies.items():\n",
    "        index_cmd = {\n",
    "            'index': {\n",
    "                '_index': 'tmdb',\n",
    "                '_type': '_doc',\n",
    "                '_id': movie_id\n",
    "            }\n",
    "        }\n",
    "        bulk_index_cmd += (json.dumps(index_cmd) + '\\n' + json.dumps(movie) + '\\n')\n",
    "\n",
    "    response = requests.post('http://localhost:9200/_bulk', data=bulk_index_cmd, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    url = 'http://localhost:9200/tmdb/_doc/_search'\n",
    "    response = requests.get(url, data=json.dumps(query), headers=headers)\n",
    "    search_hits = json.loads(response.text)['hits']\n",
    "\n",
    "    print('Num\\tRelevance Score\\tMovie Title')\n",
    "    for idx, hit in enumerate(search_hits['hits']):\n",
    "        print('%s\\t%s\\t%s' % (idx + 1, hit['_score'], hit['_source']['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\tMovie Title\n",
      "1\t81.2218\tAliens\n",
      "2\t67.8921\tCowboys & Aliens\n",
      "3\t66.59527\tThe Basketball Diaries\n",
      "4\t51.114723\tAliens vs Predator: Requiem\n",
      "5\t45.88936\tDances with Wolves\n",
      "6\t45.88936\tFriends with Benefits\n",
      "7\t45.88936\tFire with Fire\n",
      "8\t40.21931\tInterview with the Vampire\n",
      "9\t40.21931\tFrom Russia With Love\n",
      "10\t40.21931\tGone with the Wind\n",
      "11\t40.21931\tJust Go With It\n",
      "12\t40.21931\tMy Week with Marilyn\n",
      "13\t35.796352\tDie Hard: With a Vengeance\n",
      "14\t32.2498\tThe Girl with the Dragon Tattoo\n",
      "15\t32.2498\tThe Life Aquatic With Steve Zissou\n",
      "16\t32.2498\tTwin Peaks: Fire Walk with Me\n",
      "17\t7.733661\tSpace Jam\n",
      "18\t7.0542254\tThe Flintstones\n",
      "19\t6.5545254\tGalaxy Quest\n",
      "20\t6.496262\tWhite Men Can't Jump\n",
      "21\t6.320264\tBedazzled\n",
      "22\t5.806069\tThey Live\n",
      "23\t5.0928774\tBattlefield Earth\n",
      "24\t5.0928774\tCocoon\n",
      "25\t4.9547644\tHigh School Musical\n",
      "26\t1.6261511\tThe Switch\n",
      "27\t1.6142253\tNim's Island\n",
      "28\t1.6039157\tWhite Noise\n",
      "29\t1.6009648\tFrida\n",
      "30\t1.5836867\tSilver Linings Playbook\n",
      "31\t1.5588576\tThe Man in the Iron Mask\n",
      "32\t1.554282\tStrangers on a Train\n",
      "33\t1.52109\tLethal Weapon\n",
      "34\t1.4969122\tGarden State\n",
      "35\t1.4969122\tMary Poppins\n",
      "36\t1.4969122\tThe Ant Bully\n",
      "37\t1.4969122\tDays of Thunder\n",
      "38\t1.489741\t8½\n",
      "39\t1.489741\tFantastic Mr. Fox\n",
      "40\t1.4809558\tJust Friends\n"
     ]
    }
   ],
   "source": [
    "# user is most likely trying to look for the movie name space jam\n",
    "user_search = 'basketball with cartoon aliens'\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': {\n",
    "            'query': user_search,\n",
    "            # boost the title's score by 10, this can\n",
    "            # be thought of as the query weight\n",
    "            'fields': ['title^10', 'overview'],\n",
    "        }\n",
    "    },\n",
    "    'size': '40'\n",
    "}\n",
    "search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Validation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"valid\":true,\"_shards\":{\"total\":1,\"successful\":1,\"failed\":0},\"explanations\":[{\"index\":\"tmdb\",\"valid\":true,\"explanation\":\"+((title:basketball title:with title:cartoon title:aliens)^10.0 | (overview:basketball overview:with overview:cartoon overview:aliens)) #*:*\"}]}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\n",
    "   'query': {\n",
    "        'multi_match': { \n",
    "            'query': user_search,\n",
    "            'fields': ['title^10', 'overview']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# examine the underlying query strategy to understand why\n",
    "# it's generating spurious matches\n",
    "response = requests.get(\n",
    "    'http://localhost:9200/tmdb/_doc/_validate/query?explain',\n",
    "    data=json.dumps(query), headers=headers)\n",
    "\n",
    "# <fieldName>:<query>\n",
    "# title:basketball is a term query\n",
    "# title:\"space jam\" would be a phrase query, these are specified by using quotes\n",
    "# to indicate the terms should be adjacent to one another\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's 4 SHOULD clause grouped together.\n",
    "\n",
    "In Lucene, MUST clause is preceded by a +, MUST_NOT clause is preceded by a -, and the SHOULD clause isn't prefixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "tokens:\n",
      "- token: \"fire\"\n",
      "  start_offset: 0\n",
      "  end_offset: 4\n",
      "  type: \"<ALPHANUM>\"\n",
      "  position: 0\n",
      "- token: \"with\"\n",
      "  start_offset: 5\n",
      "  end_offset: 9\n",
      "  type: \"<ALPHANUM>\"\n",
      "  position: 1\n",
      "- token: \"fire\"\n",
      "  start_offset: 10\n",
      "  end_offset: 14\n",
      "  type: \"<ALPHANUM>\"\n",
      "  position: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-analyze.html\n",
    "data = {\n",
    "    'field': 'title',\n",
    "    'analyzer': 'standard',\n",
    "    'text': 'Fire with Fire'\n",
    "}\n",
    "\n",
    "response = requests.get('http://localhost:9200/tmdb/_analyze?format=yaml', \n",
    "                        data=json.dumps(data), headers=headers)\n",
    "\n",
    "# this shows information such as the resulting token, their position in the\n",
    "# original text, notice that the text has been lowercased. Allowing us to\n",
    "# inspect what tokens were indexed by the search engine\n",
    "\n",
    "# also noticed that with will be included in the index as well, that explains\n",
    "# why Fire with Fire will be a match to our query basketball with cartoon aliens\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving The Matching Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the match by changing analyzers (we can define it field by field),\n",
    "# so that our search engine can discriminate between meaningful terms and\n",
    "# those that are of low importance.\n",
    "# here we are changing the title and overview field with the English analyzer,\n",
    "# which removes stop words for us, in this case, \"with\" being one of them\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html\n",
    "mappings_setting = {\n",
    "    'mappings': {\n",
    "        # this key is the \"type\", and should match\n",
    "        # index_cmd's _type key\n",
    "        '_doc': {\n",
    "            'properties': {\n",
    "                'title': {\n",
    "                    'type': 'text',\n",
    "                    'analyzer': 'english'\n",
    "                },\n",
    "                'overview': {\n",
    "                    'type': 'text',\n",
    "                    'analyzer': 'english'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "reindex(movies, mappings_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "tokens:\n",
      "- token: \"fire\"\n",
      "  start_offset: 0\n",
      "  end_offset: 4\n",
      "  type: \"<ALPHANUM>\"\n",
      "  position: 0\n",
      "- token: \"fire\"\n",
      "  start_offset: 10\n",
      "  end_offset: 14\n",
      "  type: \"<ALPHANUM>\"\n",
      "  position: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'field': 'title',\n",
    "    'text': 'Fire with Fire'\n",
    "}\n",
    "\n",
    "response = requests.get('http://localhost:9200/tmdb/_analyze?format=yaml', \n",
    "                        data=json.dumps(data), headers=headers)\n",
    "\n",
    "# the \"with\" token is no longer is the resulting token stream\n",
    "# the positio field for the second fire term is still kept as 2\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"valid\":true,\"_shards\":{\"total\":1,\"successful\":1,\"failed\":0},\"explanations\":[{\"index\":\"tmdb\",\"valid\":true,\"explanation\":\"+((title:basketbal title:cartoon title:alien)^10.0 | (overview:basketbal overview:cartoon overview:alien)) #*:*\"}]}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can double-check the query validation and\n",
    "# see and the \"with\" token is no longer in the query strategy,\n",
    "# notice that we are also now matching the term basketbal, which\n",
    "# is the stemmed form of basketball\n",
    "user_search = 'basketball with cartoon aliens'\n",
    "query = {\n",
    "   'query': {\n",
    "        'multi_match': { \n",
    "            'query': user_search,\n",
    "            'fields': ['title^10', 'overview']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.get(\n",
    "    'http://localhost:9200/tmdb/_doc/_validate/query?explain',\n",
    "    data=json.dumps(query), headers=headers)\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\tMovie Title\n",
      "1\t71.57863\tAlien\n",
      "2\t71.57863\tAliens\n",
      "3\t71.28492\tThe Basketball Diaries\n",
      "4\t57.776596\tCowboys & Aliens\n",
      "5\t41.69649\tAliens vs Predator: Requiem\n",
      "6\t41.69649\tAVP: Alien vs. Predator\n",
      "7\t12.921349\tSpace Jam\n",
      "8\t6.8866544\tThe Flintstones\n",
      "9\t6.603108\tWhite Men Can't Jump\n",
      "10\t5.561389\tThe Thing\n",
      "11\t5.304045\tBedazzled\n",
      "12\t5.196432\tHigh School Musical\n",
      "13\t5.079732\tIndependence Day\n",
      "14\t4.98434\tThe X Files\n",
      "15\t4.6665144\tThe Day the Earth Stood Still\n"
     ]
    }
   ],
   "source": [
    "# now we can see that Space Jam is higher up the rank\n",
    "user_search = 'basketball with cartoon aliens'\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': {\n",
    "            'query': user_search,\n",
    "            'fields': ['title^10', 'overview'],\n",
    "        }\n",
    "    },\n",
    "    'size': '15'\n",
    "}\n",
    "search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposing Relevance Score With Lucene’s Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation for:  Alien\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'value': 71.57863,\n",
       " 'description': 'max of:',\n",
       " 'details': [{'value': 71.57863,\n",
       "   'description': 'sum of:',\n",
       "   'details': [{'value': 71.57863,\n",
       "     'description': 'weight(title:alien in 229) [PerFieldSimilarity], result of:',\n",
       "     'details': [{'value': 71.57863,\n",
       "       'description': 'score(doc=229,freq=1.0 = termFreq=1.0\\n), product of:',\n",
       "       'details': [{'value': 10.0, 'description': 'boost', 'details': []},\n",
       "        {'value': 5.557179,\n",
       "         'description': 'idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:',\n",
       "         'details': [{'value': 5.0, 'description': 'docFreq', 'details': []},\n",
       "          {'value': 1424.0, 'description': 'docCount', 'details': []}]},\n",
       "        {'value': 1.288039,\n",
       "         'description': 'tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:',\n",
       "         'details': [{'value': 1.0,\n",
       "           'description': 'termFreq=1.0',\n",
       "           'details': []},\n",
       "          {'value': 1.2, 'description': 'parameter k1', 'details': []},\n",
       "          {'value': 0.75, 'description': 'parameter b', 'details': []},\n",
       "          {'value': 2.2057583, 'description': 'avgFieldLength', 'details': []},\n",
       "          {'value': 1.0, 'description': 'fieldLength', 'details': []}]}]}]}]},\n",
       "  {'value': 3.460176,\n",
       "   'description': 'sum of:',\n",
       "   'details': [{'value': 3.460176,\n",
       "     'description': 'weight(overview:alien in 229) [PerFieldSimilarity], result of:',\n",
       "     'details': [{'value': 3.460176,\n",
       "       'description': 'score(doc=229,freq=1.0 = termFreq=1.0\\n), product of:',\n",
       "       'details': [{'value': 3.911321,\n",
       "         'description': 'idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:',\n",
       "         'details': [{'value': 28.0, 'description': 'docFreq', 'details': []},\n",
       "          {'value': 1423.0, 'description': 'docCount', 'details': []}]},\n",
       "        {'value': 0.8846566,\n",
       "         'description': 'tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:',\n",
       "         'details': [{'value': 1.0,\n",
       "           'description': 'termFreq=1.0',\n",
       "           'details': []},\n",
       "          {'value': 1.2, 'description': 'parameter k1', 'details': []},\n",
       "          {'value': 0.75, 'description': 'parameter b', 'details': []},\n",
       "          {'value': 36.39916, 'description': 'avgFieldLength', 'details': []},\n",
       "          {'value': 48.0,\n",
       "           'description': 'fieldLength',\n",
       "           'details': []}]}]}]}]}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can pass an additional explain argument to the\n",
    "# request when issuing the search query, then for\n",
    "# each search result returned, it will have an additional\n",
    "# \"_explanation\" entry that allows us to take a peek of\n",
    "# why we're getting the score for each search result\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': {\n",
    "            'query': user_search,\n",
    "            'fields': ['title^10', 'overview'],\n",
    "        }\n",
    "    },\n",
    "    'explain': True\n",
    "}\n",
    "\n",
    "response = requests.get('http://localhost:9200/tmdb/_doc/_search', data=json.dumps(query), headers=headers)\n",
    "result = json.loads(response.text)\n",
    "\n",
    "# we're giving title basketbal a score boost of 10\n",
    "# (tf=7.6180873) * (idf=1.0338583) * (boost=10)\n",
    "title = result['hits']['hits'][0]['_source']['title']\n",
    "print('explanation for: ', title)\n",
    "explanation = result['hits']['hits'][0]['_explanation']\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.57863, max of:\n",
      "  71.57863, sum of:\n",
      "    71.57863, weight(title:alien in 229) [PerFieldSimilarity], result of:\n",
      "      71.57863, score(doc=229,freq=1.0 = termFreq=1.0), product of:\n",
      "        10.0, boost\n",
      "        5.557179, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "          5.0, docFreq\n",
      "          1424.0, docCount\n",
      "        1.288039, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "          1.0, termFreq=1.0\n",
      "          1.2, parameter k1\n",
      "          0.75, parameter b\n",
      "          2.2057583, avgFieldLength\n",
      "          1.0, fieldLength\n",
      "  3.460176, sum of:\n",
      "    3.460176, weight(overview:alien in 229) [PerFieldSimilarity], result of:\n",
      "      3.460176, score(doc=229,freq=1.0 = termFreq=1.0), product of:\n",
      "        3.911321, idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n",
      "          28.0, docFreq\n",
      "          1423.0, docCount\n",
      "        0.8846566, tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n",
      "          1.0, termFreq=1.0\n",
      "          1.2, parameter k1\n",
      "          0.75, parameter b\n",
      "          36.39916, avgFieldLength\n",
      "          48.0, fieldLength\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def flatten_explain(explain_json, depth=0):\n",
    "    # getting rid of potential next line character to make things prettier\n",
    "    description = explain_json['description'].replace('\\n', '')\n",
    "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explain_json['value'], description)\n",
    "    if 'details' in explain_json:\n",
    "        for detail in explain_json['details']:\n",
    "            result += flatten_explain(detail, depth=depth + 1)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "print(flatten_explain(explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Space Jam vs Alien Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\tMovie Title\n",
      "1\t12.921349\tSpace Jam\n",
      "2\t6.8866544\tThe Flintstones\n",
      "3\t6.603108\tWhite Men Can't Jump\n",
      "4\t6.0548387\tAliens vs Predator: Requiem\n",
      "5\t5.561389\tThe Thing\n",
      "6\t5.304045\tBedazzled\n",
      "7\t5.196432\tHigh School Musical\n",
      "8\t5.079732\tIndependence Day\n",
      "9\t4.98434\tThe X Files\n",
      "10\t4.6665144\tThe Day the Earth Stood Still\n"
     ]
    }
   ],
   "source": [
    "# even though we get the desired result by making\n",
    "# some changes to the search query:\n",
    "# Here are some questions to ask ourselves:\n",
    "# the \"|\" is taking the maximum of the two compound queries,\n",
    "# will this streategy work for other searches\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': { \n",
    "            'query': user_search,\n",
    "            'fields': ['title^0.1', 'overview'],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "search(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
