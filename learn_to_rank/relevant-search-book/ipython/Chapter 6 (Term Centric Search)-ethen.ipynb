{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Term-Centric-Search\" data-toc-modified-id=\"Term-Centric-Search-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Term Centric Search</a></span><ul class=\"toc-item\"><li><span><a href=\"#Copy-Fields\" data-toc-modified-id=\"Copy-Fields-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Copy Fields</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Centric Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field centric search is based on search criteria such as whether the search matches an exact field or whether the search matches some of the fields. Term centric, on the other hands, places the search terms front and center.\n",
    "\n",
    "Instead of searching every field with the full search string, term centric search acts on the search string like a term-by-term matchmaker, trying to find each term's ideal match, i.e. for each term go through each field and find the term's best matching field, only then do we combine the score for each term.\n",
    "\n",
    "The reason that we should be considering term-centric search is to solve for two potential problems:\n",
    "\n",
    "**A failure to give a higher rank to documents that match more search terms.**\n",
    "\n",
    "Imagine the following scenario:\n",
    "\n",
    "```python\n",
    "# If we are to index two documents:\n",
    "doc1 = {'title': 'albino', 'body': 'elephant'}\n",
    "doc2 = {'title': 'elephant', 'body': 'elephant'}\n",
    "\n",
    "# then we issue a 'most_fields' type query 'albino elephant' over the title and body field.\n",
    "```\n",
    "\n",
    "In the field-centric search scenario, both documents would be equally ranked since we are shipping the entire search string to each field for scoring before combining the result. There is no difference between a match in which only elephant matches both fields, and a match in which albino matches one field and elephant matches another\n",
    "\n",
    "**Signal discordance.** Unintuitive relevance scoring based on constituent parts instead of scoring based on larger parts. e.g. instead of searching for the whole document's text as a whole, our source data model might have split up the document into various fields such as title, intro, conclusion, appendix. And if we send the search query to these fields separately, it will create a signal discordance where the signal that we are using doesn't reflect the user's intent.\n",
    "\n",
    "Term-centric search aims to solve the albino elephant problem and signal discordance by taking a top-down view of search: breaking up search terms, and querying each term one by one against a set of fields. Note that we'll soon realize that term-centric field is not without its problems and a hybrid approach may be preferred.\n",
    "\n",
    "Links that describes potential issues with field-centric search: https://www.elastic.co/guide/en/elasticsearch/guide/master/field-centric.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poster_path': '/mfMndRWFbzXbTx0g3rHUXFAxyOh.jpg',\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'revenue': 0,\n",
       " 'overview': 'When the FBI hires her to go undercover at a college sorority, Molly Morris (Miley Cyrus) must transform herself from a tough, streetwise private investigator to a refined, sophisticated university girl to help protect the daughter of a one-time Mobster. With several suspects on her list, Molly unexpectedly discovers that not everyone is who they appear to be, including herself.',\n",
       " 'video': False,\n",
       " 'id': 93837,\n",
       " 'genres': [{'id': 28, 'name': 'Action'}, {'id': 35, 'name': 'Comedy'}],\n",
       " 'title': 'So Undercover',\n",
       " 'tagline': \"Meet the FBI's new secret weapon\",\n",
       " 'vote_count': 55,\n",
       " 'homepage': '',\n",
       " 'belongs_to_collection': None,\n",
       " 'original_language': 'en',\n",
       " 'status': 'Released',\n",
       " 'spoken_languages': [{'iso_639_1': 'en', 'name': 'English'}],\n",
       " 'imdb_id': 'tt1766094',\n",
       " 'adult': False,\n",
       " 'backdrop_path': '/o4Tt60z94Hbgk8adeZG9WE4S2im.jpg',\n",
       " 'production_companies': [{'name': 'Exclusive Media Group', 'id': 11448}],\n",
       " 'release_date': '2012-01-01',\n",
       " 'popularity': 0.345124796829192,\n",
       " 'original_title': 'So Undercover',\n",
       " 'budget': 0,\n",
       " 'cast': [{'name': 'Miley Cyrus',\n",
       "   'character': 'Molly',\n",
       "   'id': 76594,\n",
       "   'credit_id': '52fe49419251416c750c21c9',\n",
       "   'cast_id': 10,\n",
       "   'profile_path': '/4cWl6nJTQMexqZFFDfaJucwhqGY.jpg',\n",
       "   'order': 0},\n",
       "  {'name': 'Joshua Bowman',\n",
       "   'character': 'Nicholas',\n",
       "   'id': 139835,\n",
       "   'credit_id': '52fe49419251416c750c21cd',\n",
       "   'cast_id': 11,\n",
       "   'profile_path': '/FOSRcKOJqCZzpFhBCzlEphp5F.jpg',\n",
       "   'order': 1},\n",
       "  {'name': 'Eloise Mumford',\n",
       "   'character': 'Sasha',\n",
       "   'id': 222130,\n",
       "   'credit_id': '52fe49419251416c750c21d1',\n",
       "   'cast_id': 12,\n",
       "   'profile_path': '/6yT9OjHcnG55iGjq7XFvd2qpYT2.jpg',\n",
       "   'order': 2},\n",
       "  {'name': 'Jeremy Piven',\n",
       "   'character': 'Armon',\n",
       "   'id': 12799,\n",
       "   'credit_id': '52fe49419251416c750c21d5',\n",
       "   'cast_id': 13,\n",
       "   'profile_path': '/qtho4ZUcValnVvscTGgyWfUr4VP.jpg',\n",
       "   'order': 3},\n",
       "  {'name': 'Autumn Reeser',\n",
       "   'character': 'Bizzy',\n",
       "   'id': 74607,\n",
       "   'credit_id': '52fe49419251416c750c21d9',\n",
       "   'cast_id': 14,\n",
       "   'profile_path': '/vZlZQkQzQ0PSCnQT77vqEFnYsoO.jpg',\n",
       "   'order': 4},\n",
       "  {'name': 'Alexis Knapp',\n",
       "   'character': 'Taylor',\n",
       "   'id': 999790,\n",
       "   'credit_id': '52fe49419251416c750c21dd',\n",
       "   'cast_id': 15,\n",
       "   'profile_path': '/jhQeoRHhCig8dtJxthKChQmAERQ.jpg',\n",
       "   'order': 5},\n",
       "  {'name': 'Matthew Settle',\n",
       "   'character': 'Professor Talloway',\n",
       "   'id': 33286,\n",
       "   'credit_id': '52fe49419251416c750c21e1',\n",
       "   'cast_id': 16,\n",
       "   'profile_path': '/neODd3vTVEb7TXOWEZC44ZZu1yk.jpg',\n",
       "   'order': 6},\n",
       "  {'name': 'Megan Park',\n",
       "   'character': 'Cotton',\n",
       "   'id': 55615,\n",
       "   'credit_id': '52fe49419251416c750c21e5',\n",
       "   'cast_id': 17,\n",
       "   'profile_path': '/AjIaQKbjMgYcJxalCBM4MGREss0.jpg',\n",
       "   'order': 7},\n",
       "  {'name': \"Mike O'Malley\",\n",
       "   'character': 'Sam',\n",
       "   'id': 87192,\n",
       "   'credit_id': '52fe49419251416c750c21e9',\n",
       "   'cast_id': 18,\n",
       "   'profile_path': '/9VwiKnQySJN7buvCg53v4NB5Tj7.jpg',\n",
       "   'order': 8},\n",
       "  {'name': 'Kelly Osbourne',\n",
       "   'character': 'Becky',\n",
       "   'id': 178425,\n",
       "   'credit_id': '52fe49419251416c750c21ed',\n",
       "   'cast_id': 19,\n",
       "   'profile_path': '/ub2UobCm9Fe4PYWgerPQkdXMSQA.jpg',\n",
       "   'order': 9},\n",
       "  {'name': 'Lauren McKnight',\n",
       "   'character': 'Alex',\n",
       "   'id': 560298,\n",
       "   'credit_id': '52fe49419251416c750c21f1',\n",
       "   'cast_id': 20,\n",
       "   'profile_path': None,\n",
       "   'order': 10}],\n",
       " 'directors': [{'name': 'Tom Vaughan',\n",
       "   'department': 'Directing',\n",
       "   'job': 'Director',\n",
       "   'credit_id': '52fe49419251416c750c2195',\n",
       "   'profile_path': '/opDMR3lConDBNSiVmqt4h6TMFBF.jpg',\n",
       "   'id': 56717}],\n",
       " 'vote_average': 5.9,\n",
       " 'runtime': 94}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract():\n",
    "    with open('tmdb.json') as f:\n",
    "        return json.loads(f.read())\n",
    "    \n",
    "    \n",
    "movies = extract()\n",
    "\n",
    "# we can check some sample movie id, to check a sense of what\n",
    "# the data looks like\n",
    "# movie_ids = ['93837', '8193', '8195', '5', '8202', '11']\n",
    "movies['93837']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticSearchUtils:\n",
    "\n",
    "    def __init__(self, index_name='tmdb', base_url='http://localhost:9200'):\n",
    "        self.base_url = base_url\n",
    "        self.index_name = index_name\n",
    "        self.index_url = self.base_url + '/' + self.index_name\n",
    "        self.index_type_name = '_doc'\n",
    "        self.index_type_url = self.index_url + '/' + self.index_type_name\n",
    "        self.headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    def reindex(self, movies, analysis_settings, mapping_settings=None):\n",
    "        \"\"\"\n",
    "        Reindex takes analyzer and field mappings, recreates the index, and then reindexes\n",
    "        TMDB movies using the _bulk index API. There are other ways for modifying the configuration\n",
    "        of the index besides dropping and restarting, however for convenience and because our data\n",
    "        isn't truly that large, we'll just delete and start from scratch when we need to.\n",
    "        \"\"\"\n",
    "        response = requests.delete(self.index_url)\n",
    "        print('deleted TMDB index: ', response.status_code)\n",
    "\n",
    "        # create the index with explicit settings\n",
    "        # We need to explicitly set number of shards to 1 to eliminate the impact of \n",
    "        # distributed IDF on our small collection\n",
    "        # See also 'Relavance is Broken!'\n",
    "        # http://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-is-broken.html\n",
    "        settings = {\n",
    "            'settings': {\n",
    "                'index': {\n",
    "                    'number_of_replicas': 1,\n",
    "                    'number_of_shards': 1\n",
    "                },\n",
    "                'analysis': analysis_settings\n",
    "            }\n",
    "        }\n",
    "        if mapping_settings is not None:\n",
    "            settings['mappings'] = mapping_settings\n",
    "\n",
    "        response = requests.put(self.index_url, data=json.dumps(settings), headers=self.headers)\n",
    "        print('Created TMDB index: ', response.status_code)\n",
    "\n",
    "        self._bulk_index(movies)\n",
    "\n",
    "    def _bulk_index(self, movies):\n",
    "        bulk_index_cmd = ''\n",
    "        for movie_id, movie in movies.items():\n",
    "            index_cmd = {\n",
    "                'index': {\n",
    "                    '_index': self.index_name,\n",
    "                    '_type': self.index_type_name,\n",
    "                    '_id': movie_id\n",
    "                }\n",
    "            }\n",
    "            bulk_index_cmd += (json.dumps(index_cmd) + '\\n' + json.dumps(movie) + '\\n')\n",
    "\n",
    "        response = requests.post(self.base_url + '/_bulk',\n",
    "                                 data=bulk_index_cmd,\n",
    "                                 headers=self.headers)\n",
    " \n",
    "        print('Bulk index into TMDB index:', response.status_code)\n",
    "\n",
    "    def search(self, query, verbose=False):\n",
    "        search_url = self.index_type_url + '/_search'\n",
    "        response = requests.get(search_url, data=json.dumps(query), headers=self.headers)\n",
    "\n",
    "        search_hits = json.loads(response.text)['hits']['hits']\n",
    "        for idx, hit in enumerate(search_hits):\n",
    "            source = hit['_source']\n",
    "            print(\"%s\\t%s\\t%s\" % (idx + 1, hit['_score'], source['title']))\n",
    "            \n",
    "            if verbose:\n",
    "                cast_names = []\n",
    "                cast_characters = []\n",
    "                for cast in source['cast']:\n",
    "                    cast_names.append(cast['name'])\n",
    "                    cast_characters.append(cast['character'])\n",
    "\n",
    "                director_names = [director['name'] for director in source['directors']]\n",
    "\n",
    "                print('director: ', director_names)\n",
    "                print('cast: ', cast_names)\n",
    "                print('character: ', cast_characters)\n",
    "                print('overview:', source['overview'])\n",
    "                if '_explanation' in hit:\n",
    "                    result = ElasticSearchUtils.flatten_explain(hit['_explanation'])\n",
    "                    print(result)\n",
    "\n",
    "                print('=============================================')\n",
    "   \n",
    "    @staticmethod          \n",
    "    def flatten_explain(explain_json, depth=0):\n",
    "        \n",
    "        # getting rid of potential next line character to make things prettier\n",
    "        description = explain_json['description'].replace('\\n', '')\n",
    "        result = ' ' * (depth * 2) + '%s, %s\\n' % (explain_json['value'], description)\n",
    "        if 'details' in explain_json:\n",
    "            for detail in explain_json['details']:\n",
    "                result += ElasticSearchUtils.flatten_explain(detail, depth=depth + 1)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def validate(self, query):\n",
    "        url = self.index_type_url + '/_validate/query?explain'\n",
    "        response = requests.get(url, data=json.dumps(query), headers=self.headers)\n",
    "        return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted TMDB index:  200\n",
      "Created TMDB index:  200\n",
      "Bulk index into TMDB index: 200\n"
     ]
    }
   ],
   "source": [
    "# re-creating the index from chapter 5\n",
    "analysis_settings = {\n",
    "    'filter': {\n",
    "        'bigram_filter': {\n",
    "            'type': 'shingle',\n",
    "            'max_shingle_size': 2,\n",
    "            'min_shingle_size': 2,\n",
    "            'output_unigrams': False\n",
    "        },\n",
    "        'english_stemmer': {\n",
    "            'type': 'stemmer',\n",
    "            'name': 'english'\n",
    "        }\n",
    "    },\n",
    "    'analyzer': {\n",
    "        'english_bigram': {\n",
    "            'type': 'custom',\n",
    "            'tokenizer': 'standard',\n",
    "            'filter': ['lowercase', 'english_stemmer', 'bigram_filter']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "mapping_settings = {\n",
    "    '_doc': {\n",
    "        'properties': {\n",
    "            'cast': {\n",
    "                'properties': {\n",
    "                    'name': {\n",
    "                        'type': 'text',\n",
    "                        'analyzer': 'english',\n",
    "                        'fields': {\n",
    "                            'bigrammed': {\n",
    "                                'type': 'text',\n",
    "                                'analyzer': 'english_bigram'\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'directors': {\n",
    "                'properties': {\n",
    "                    'name': {\n",
    "                        'type': 'text',\n",
    "                        'analyzer': 'english',\n",
    "                        'fields': {\n",
    "                            'bigrammed': {\n",
    "                                'type': 'text',\n",
    "                                'analyzer': 'english_bigram'\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es_utils = ElasticSearchUtils()\n",
    "es_utils.reindex(movies, analysis_settings, mapping_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 'tmdb',\n",
       "  'valid': True,\n",
       "  'explanation': '+((directors.name.bigrammed:star trek directors.name.bigrammed:trek patrick directors.name.bigrammed:patrick stewart directors.name.bigrammed:stewart william directors.name.bigrammed:william shatner) | (cast.name.bigrammed:star trek cast.name.bigrammed:trek patrick cast.name.bigrammed:patrick stewart cast.name.bigrammed:stewart william cast.name.bigrammed:william shatner)^5.0 | (overview:star overview:trek overview:patrick overview:stewart overview:william overview:shatner) | (title:star title:trek title:patrick title:stewart title:william title:shatner))~1.0 #*:*'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# field centric search\n",
    "# the only link documents search in depth\n",
    "# https://www.elastic.co/guide/en/elasticsearch/guide/master/term-vs-full-text.html\n",
    "user_search = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': { \n",
    "            'query': user_search,\n",
    "            'type': 'most_fields',\n",
    "            'fields': [\n",
    "                'title',\n",
    "                'overview',\n",
    "                'cast.name.bigrammed^5',\n",
    "                'directors.name.bigrammed'\n",
    "            ]\n",
    "         }\n",
    "    }\n",
    "}\n",
    "# checking the translated lucene query\n",
    "es_utils.validate(query)['explanations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t64.98588\tStar Trek: Generations\n",
      "2\t41.540653\tStar Trek IV: The Voyage Home\n",
      "3\t40.866093\tStar Trek V: The Final Frontier\n",
      "4\t38.89132\tStar Trek: Nemesis\n",
      "5\t38.43622\tStar Trek: Insurrection\n"
     ]
    }
   ],
   "source": [
    "query.update({'size': 5, 'explain': True})\n",
    "es_utils.search(query, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The potential problem with field centric search is that term frequencies are different in each field and could interfere with each other to produce badly ordered results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid': True,\n",
       " '_shards': {'total': 1, 'successful': 1, 'failed': 0},\n",
       " 'explanations': [{'index': 'tmdb',\n",
       "   'valid': True,\n",
       "   'explanation': '+((directors.name.bigrammed:star trek directors.name.bigrammed:trek patrick directors.name.bigrammed:patrick stewart directors.name.bigrammed:stewart william directors.name.bigrammed:william shatner) | (cast.name.bigrammed:star trek cast.name.bigrammed:trek patrick cast.name.bigrammed:patrick stewart cast.name.bigrammed:stewart william cast.name.bigrammed:william shatner) | (overview:star overview:trek overview:patrick overview:stewart overview:william overview:shatner) | (title:star title:trek title:patrick title:stewart title:william title:shatner)) #*:*'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term centric search using 'query_string'\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html\n",
    "user_search = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'query_string': { \n",
    "            'query': user_search,\n",
    "            'fields': [\n",
    "                'title',\n",
    "                'overview',\n",
    "                'cast.name.bigrammed',\n",
    "                'directors.name.bigrammed'\n",
    "            ]      \n",
    "         }\n",
    "    }\n",
    "}\n",
    "\n",
    "# checking the translated lucene query\n",
    "es_utils.validate(query)['explanations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t10.409781\tStar Trek: Generations\n",
      "2\t9.918423\tHannah Montana: The Movie\n",
      "3\t8.972326\tStar Trek: Insurrection\n",
      "4\t8.972326\tStar Trek: Nemesis\n",
      "5\t8.380948\tStar Trek IV: The Voyage Home\n"
     ]
    }
   ],
   "source": [
    "query.update({'size': 5, 'explain': True})\n",
    "es_utils.search(query, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy fields comes from the idea that we can combine/group multiple similar fields into one single field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted TMDB index:  200\n",
      "Created TMDB index:  200\n",
      "Bulk index into TMDB index: 200\n"
     ]
    }
   ],
   "source": [
    "# here we combine the various field about people (cast and director) into a single\n",
    "# field that provides a specific signal, this solves for the signal discordance\n",
    "# problem where fields are scored independently, resulting in different search term's\n",
    "# idf score being different in different field\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/copy-to.html\n",
    "mapping_settings = {\n",
    "    '_doc': {\n",
    "        'properties': {\n",
    "            'title': {\n",
    "                'type': 'text',\n",
    "                'analyzer': 'english'\n",
    "            },\n",
    "            'overview': {\n",
    "                'type': 'text',\n",
    "                'analyzer': 'english'\n",
    "            },\n",
    "            'cast': {\n",
    "                'properties': {\n",
    "                    'name': {\n",
    "                        'type': 'text',\n",
    "                        'analyzer': 'english',\n",
    "                        'copy_to': 'people.name',\n",
    "                        'fields': {\n",
    "                            'bigrammed': {\n",
    "                                'type': 'text',\n",
    "                                'analyzer': 'english_bigram'\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'directors': {\n",
    "                'properties': {\n",
    "                    'name': {\n",
    "                        'type': 'text',\n",
    "                        'analyzer': 'english',\n",
    "                        'copy_to': 'people.name',\n",
    "                        'fields': {\n",
    "                            'bigrammed': {\n",
    "                                'type': 'text',\n",
    "                                'analyzer': 'english_bigram'\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'people': {  # define the combined field people like any other field\n",
    "                'properties': {\n",
    "                    'name': {\n",
    "                        'type': 'text',\n",
    "                        'analyzer': 'english',\n",
    "                        'fields': {\n",
    "                            'bigrammed': {\n",
    "                                'type': 'text',\n",
    "                                'analyzer': 'english_bigram'\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "es_utils.reindex(movies, analysis_settings, mapping_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t13.463219\tStar Trek: Generations\n",
      "2\t10.10991\tStar Trek V: The Final Frontier\n",
      "3\t8.345118\tConspiracy Theory\n",
      "4\t8.305401\tBill & Ted's Bogus Journey\n",
      "5\t8.271045\tMiss Congeniality 2: Armed and Fabulous\n"
     ]
    }
   ],
   "source": [
    "# performing a search on the combined field people\n",
    "user_search = 'patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'match': { \n",
    "            'people.name': user_search\n",
    "         }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "es_utils.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 'tmdb',\n",
       "  'valid': True,\n",
       "  'explanation': '+((blended(terms:[directors.name.bigrammed:patrick stewart, cast.name.bigrammed:patrick stewart]) blended(terms:[directors.name.bigrammed:stewart william, cast.name.bigrammed:stewart william]) blended(terms:[directors.name.bigrammed:william shatner, cast.name.bigrammed:william shatner])) | (blended(terms:[overview:patrick, title:patrick]) blended(terms:[overview:stewart, title:stewart]) blended(terms:[overview:william, title:william]) blended(terms:[overview:shatner, title:shatner]))) #*:*'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using cross field query to do term-centric search,\n",
    "# cross field treats all the field as one big field,\n",
    "# and looks for each term in any of the fields\n",
    "# https://www.elastic.co/guide/en/elasticsearch/guide/master/_cross_fields_queries.html\n",
    "user_search = 'patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': {\n",
    "            'query': user_search,\n",
    "            'type': 'cross_fields',\n",
    "            'fields': [\n",
    "                'title',\n",
    "                'overview',\n",
    "                'cast.name.bigrammed',\n",
    "                'directors.name.bigrammed'\n",
    "            ]   \n",
    "         }\n",
    "    }\n",
    "}\n",
    "\n",
    "# checking the translated lucene query\n",
    "es_utils.validate(query)['explanations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When validating our `cross_fields` query, we get a \"blended\" query. This aims to solve the term-frequency problem by blending inverse document frequencies across fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t32.55439\tStar Trek: Generations\n",
      "2\t20.593908\tStar Trek: Insurrection\n",
      "3\t20.580242\tStar Trek: Nemesis\n",
      "4\t20.264835\tStar Trek II: The Wrath of Khan\n",
      "5\t19.561811\tStar Trek V: The Final Frontier\n",
      "6\t19.235165\tStar Trek IV: The Voyage Home\n",
      "7\t19.125366\tStar Trek: First Contact\n",
      "8\t19.10784\tStar Trek: The Motion Picture\n",
      "9\t18.711422\tStar Trek III: The Search for Spock\n",
      "10\t17.318808\tStar Trek VI: The Undiscovered Country\n"
     ]
    }
   ],
   "source": [
    "# combining two searches\n",
    "# a first level search that is more greedy, used to increase to recall size\n",
    "# and a second level is more stringent, used to increase precision\n",
    "user_search = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'bool': {\n",
    "            'should': [\n",
    "                {\n",
    "                    # first level: cast a wide net by searching over all the fields\n",
    "                    'multi_match': {\n",
    "                        'query': user_search,\n",
    "                        'type': 'cross_fields',\n",
    "                        'fields': [\n",
    "                            'overview',\n",
    "                            'title',\n",
    "                            'directors.name',\n",
    "                            'cast.name'\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    # second level: being more stringent and search only on\n",
    "                    # a subset of the fields\n",
    "                    'multi_match': {\n",
    "                        'query': user_search,\n",
    "                        'type': 'cross_fields',\n",
    "                        'fields': [\n",
    "                            'directors.name.bigrammed',\n",
    "                            'cast.name.bigrammed'\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "es_utils.search(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "266px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
