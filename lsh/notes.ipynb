{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/soundcloud/cosine-lsh-join-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download(url, filename):\n",
    "    with open(filename, \"wb\") as file:\n",
    "        response = requests.get(url)\n",
    "        file.write(response.content)\n",
    "\n",
    "\n",
    "DATA_DIR = './datasets/'\n",
    "URL = 'http://nlp.stanford.edu/data/glove.twitter.27B.zip'\n",
    "filename = os.path.join(DATA_DIR, 'glove.twitter.27B.zip')\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    download(URL, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:  (954811, 25)\n",
      "testing data shape:  (238703, 25)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_train_test_data(filename):\n",
    "    dimension = 25  # valid values 25, 50, 100, 200\n",
    "    test_size = 0.2\n",
    "    random_state = 1234\n",
    "\n",
    "    with zipfile.ZipFile(filename) as f:\n",
    "        X = []\n",
    "        zip_filename = 'glove.twitter.27B.{}d.txt'.format(dimension)\n",
    "        for line in f.open(zip_filename):\n",
    "            # remove the first index, id field and only get the vectors\n",
    "            vector = np.array([float(x) for x in line.strip().split()[1:]])\n",
    "            X.append(vector)\n",
    "\n",
    "        X_train, X_test = train_test_split(\n",
    "            np.array(X), test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # downsample for experimentation purpose\n",
    "    # X_train = X_train[:50000]\n",
    "    # X_test = X_test[:10000]\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "X_train, X_test = get_train_test_data(filename)\n",
    "print('training data shape: ', X_train.shape)\n",
    "print('testing data shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "class BruteForce:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        lens = (X ** 2).sum(axis=-1)\n",
    "        index = X / np.sqrt(lens)[:, np.newaxis]\n",
    "        self.index_ = np.ascontiguousarray(index, dtype=np.float32)\n",
    "        return self\n",
    "\n",
    "    def query(self, vector, topn):\n",
    "        \"\"\"Find indices of `n` most similar vectors from the index to query vector `v`.\"\"\"\n",
    "\n",
    "        # argmax_a dot(a, b) / |a||b| = argmin_a -dot(a, b)\n",
    "        dists = -np.dot(self.index_, vector)\n",
    "        indices = np.argpartition(dists, topn)[:topn]\n",
    "        return sorted(indices, key=lambda index: dists[index])\n",
    "\n",
    "\n",
    "class KDTree:\n",
    "\n",
    "    def __init__(self, topn=10, n_jobs=-1):\n",
    "        self.topn = topn\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X):\n",
    "        X_normed = normalize(X)\n",
    "        index = NearestNeighbors(\n",
    "            n_neighbors=self.topn, metric='euclidean', n_jobs=self.n_jobs)\n",
    "        index.fit(X_normed)\n",
    "        self.index_ = index\n",
    "        return self\n",
    "\n",
    "    def query_batch(self, X):\n",
    "        X_normed = normalize(X)\n",
    "        _, indices = self.index_.kneighbors(X_normed)\n",
    "        return indices\n",
    "\n",
    "    def query(self, vector):\n",
    "        \"\"\"Find indices of `n` most similar vectors from the index to query vector `v`.\"\"\"\n",
    "        vector_normed = normalize(vector.reshape(1, -1))\n",
    "        _, indices = self.index_.kneighbors(vector_normed)\n",
    "        return indices.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def get_ground_truth(X_train, X_test, kdtree_params):\n",
    "    start = time.time()\n",
    "    kdtree = KDTree()\n",
    "    kdtree.fit(X_train)\n",
    "    build_time = time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    indices = kdtree.query_batch(X_test)\n",
    "    search_time = time.time() - start\n",
    "\n",
    "    ground_truth = [(vector, index) for vector, index in zip(X_test, indices)]\n",
    "    return build_time, search_time, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth filepath:  model/ground_truth.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.84227,  0.19005,  1.5346 ,  0.88995, -1.6548 , -0.60046,\n",
       "        -1.3206 , -1.5521 , -0.30763, -0.56361,  1.5054 ,  3.2881 ,\n",
       "         1.7582 , -0.63313, -0.48781,  2.0016 , -2.5334 ,  1.0601 ,\n",
       "        -0.19666, -0.38252,  0.65653,  0.89475,  2.7882 ,  2.4109 ,\n",
       "        -0.72981]),\n",
       " array([213945, 566700, 232533, 673941,  79801, 932371,  59183, 318977,\n",
       "        649659, 871934]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "MODEL_DIR = 'model'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "ground_truth_filename = 'ground_truth.pkl'\n",
    "ground_truth_filepath = os.path.join(MODEL_DIR, ground_truth_filename)\n",
    "print('ground truth filepath: ', ground_truth_filepath)\n",
    "\n",
    "if os.path.exists(ground_truth_filepath):\n",
    "    ground_truth = load(ground_truth_filepath)\n",
    "else:\n",
    "    # using a setting of kdtree_params = {'topn': 10, 'n_jobs': -1},\n",
    "    # it took at least 1 hour to finish on a 8 core laptop\n",
    "    kdtree_params = {'topn': 10, 'n_jobs': -1}\n",
    "    build_time, search_time, ground_truth = get_ground_truth(X_train, X_test, kdtree_params)\n",
    "    dump(ground_truth, ground_truth_filepath)\n",
    "\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    "\n",
    "\n",
    "class Hnsw:\n",
    "\n",
    "    def __init__(self, index_params=None, query_params=None, print_progress=True):\n",
    "        self.index_params = index_params\n",
    "        self.query_params = query_params\n",
    "        self.print_progress = print_progress\n",
    "\n",
    "    def fit(self, X):\n",
    "        index_params = self.index_params\n",
    "        if index_params is None:\n",
    "            index_params = {'M': 16, 'post': 0, 'efConstruction': 400}\n",
    "\n",
    "        query_params = self.query_params\n",
    "        if query_params is None:\n",
    "            query_params = {'ef': 90}\n",
    "\n",
    "        index = nmslib.init(space='cosinesimil', method='hnsw')\n",
    "        index.addDataPointBatch(X)\n",
    "        index.createIndex(index_params, print_progress=self.print_progress)\n",
    "        index.setQueryTimeParams(query_params)\n",
    "\n",
    "        self.index_ = index\n",
    "        self.index_params_ = index_params\n",
    "        self.query_params_ = query_params\n",
    "        return self\n",
    "\n",
    "    def query(self, vector, topn):\n",
    "        indices, distances = self.index_.knnQuery(vector, k=topn)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369.5593509674072"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "hnsw = Hnsw()\n",
    "hnsw.fit(X_train)\n",
    "build_time = time.time() - start\n",
    "build_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002225160598754883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([213945, 566700, 232533, 673941, 932371,  59183, 318977, 649659,\n",
       "       871934, 221617], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn = 10\n",
    "\n",
    "query_vector, correct_indices = ground_truth[0]\n",
    "start = time.time()\n",
    "found_indices = hnsw.query(query_vector, topn)\n",
    "search_time = time.time() - start\n",
    "print(search_time)\n",
    "found_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = len(set(found_indices).intersection(correct_indices)) / topn\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def run_algo(X_train, X_test, topn, ground_truth, algo_type, algo_params):\n",
    "    \n",
    "    if algo_type == 'hsnw':\n",
    "        algo = Hnsw()\n",
    "    elif algo_type == 'n2':\n",
    "        algo = N2()\n",
    "\n",
    "    start = time.time()\n",
    "    algo.fit(X_train)\n",
    "    build_time = time.time() - start\n",
    "\n",
    "    total_correct = 0\n",
    "    total_search_time = 0.0\n",
    "    n_queries = len(ground_truth)\n",
    "    for i in trange(n_queries):\n",
    "        query_vector, correct_indices = ground_truth[i]\n",
    "\n",
    "        start = time.time()\n",
    "        found_indices = algo.query(query_vector, topn)\n",
    "        search_time = time.time() - start\n",
    "        total_search_time += search_time\n",
    "\n",
    "        n_correct = len(set(found_indices).intersection(correct_indices))\n",
    "        total_correct += n_correct\n",
    "\n",
    "    avg_search_time = total_search_time / n_queries\n",
    "    avg_precision = total_correct / (n_queries * topn)\n",
    "    return build_time, avg_search_time, avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238703/238703 [00:46<00:00, 5136.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build time:  292.62172412872314\n",
      "average search time:  0.00016463863871264096\n",
      "average precision:  0.9770141137731826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "algo_type = 'hsnw'\n",
    "algo_params = {\n",
    "    'index_params': {'M': 16, 'post': 0, 'efConstruction': 100}\n",
    "}\n",
    "\n",
    "build_time, avg_search_time, avg_precision = run_algo(\n",
    "    X_train, X_test, topn, ground_truth, algo_type, algo_params)\n",
    "print('build time: ', build_time)\n",
    "print('average search time: ', avg_search_time)\n",
    "print('average precision: ', avg_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238703/238703 [00:45<00:00, 5289.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build time:  308.47004795074463\n",
      "average search time:  0.00015883217352200492\n",
      "average precision:  0.9770610340045999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "build_time, avg_search_time, avg_precision = run_algo(\n",
    "    X_train, X_test, topn, ground_truth)\n",
    "print('build time: ', build_time)\n",
    "print('average search time: ', avg_search_time)\n",
    "print('average precision: ', avg_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from n2 import HnswIndex\n",
    "\n",
    "class N2:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        index = HnswIndex(dimension=X.shape[1])\n",
    "        for vector in X:\n",
    "            index.add_data(vector)\n",
    "\n",
    "        index.build(m=16, ef_construction=200, n_threads=8)\n",
    "        self.index_ = index\n",
    "        return self\n",
    "\n",
    "    def query(self, vector, topn):\n",
    "        indices = self.index_.search_by_vector(vector, k=topn, ef_search=50)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.39423203468323"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "n2 = N2()\n",
    "n2.fit(X_train)\n",
    "build_time = time.time() - start\n",
    "build_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003478527069091797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[232533, 213945, 932371, 673941, 566700, 59183, 318977, 221617, 431056, 908013]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn = 10\n",
    "\n",
    "query_vector, correct_indices = ground_truth[0]\n",
    "start = time.time()\n",
    "# found_indices = n2.query(query_vector, topn)\n",
    "found_indices = n2.index_.search_by_vector(query_vector, k=topn, ef_search=100)\n",
    "search_time = time.time() - start\n",
    "print(search_time)\n",
    "found_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([213945, 566700, 232533, 673941,  79801, 932371,  59183, 318977,\n",
       "       649659, 871934])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = len(set(found_indices).intersection(correct_indices)) / topn\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238703/238703 [00:22<00:00, 10387.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build time:  170.42729496955872\n",
      "average search time:  8.815961418996128e-05\n",
      "average precision:  0.5988177777405395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "algo_type = 'n2'\n",
    "topn = 10\n",
    "build_time, avg_search_time, avg_precision = run_algo(X_train, X_test, topn, ground_truth, algo_type)\n",
    "print('build time: ', build_time)\n",
    "print('average search time: ', avg_search_time)\n",
    "print('average precision: ', avg_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-55ca6286e3e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hi' is not defined"
     ]
    }
   ],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    "\n",
    "index = nmslib.init(space='cosinesimil', method='hnsw')\n",
    "# for i, x in enumerate(X):\n",
    "#     nmslib.addDataPoint(self._index, i, x.tolist())\n",
    "\n",
    "#index.addDataPointBatch(X_train)\n",
    "\n",
    "#index_params = {'post': 2}\n",
    "#index.createIndex(index_params, print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from n2 import HnswIndex\n",
    "\n",
    "\n",
    "index_params = {'M': 16, 'post': 0, 'efConstruction': 400}\n",
    "query_params = {'ef': 90}\n",
    "\n",
    "N, dim = 10240, 20\n",
    "samples = np.arange(N * dim).reshape(N, dim)\n",
    "\n",
    "index = HnswIndex(dim)\n",
    "for sample in samples:\n",
    "    index.add_data(sample)\n",
    "index.build(m=16, ef_construction=400, n_threads=8)\n",
    "print(index.search_by_id(0, 10))\n",
    "# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 37, 38, 39, 40]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search_by_vector(samples[0], k=5, ef_search=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbours = index.knnQueryBatch(data, k=10, num_threads=4)\n",
    "ids, distances = index.knnQuery(X_test[0], k=10)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(self._index_name):\n",
    "#     logging.debug(\"Loading index from file\")\n",
    "#     nmslib.loadIndex(self._index, self._index_name)\n",
    "# else:\n",
    "#     logging.debug(\"Create Index\")\n",
    "#     nmslib.createIndex(self._index, self._index_param)\n",
    "#     if self._save_index:\n",
    "#         nmslib.saveIndex(self._index, self._index_name)\n",
    "\n",
    "# nmslib.setQueryTimeParams(self._index, self._query_param)\n",
    "\n",
    "# def query(self, v, n):\n",
    "# import nmslib\n",
    "# return nmslib.knnQuery(self._index, n, v.tolist())\n",
    "\n",
    "# def freeIndex(self):\n",
    "# import nmslib\n",
    "# nmslib.freeIndex(self._index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    "\n",
    "\n",
    "# initialize a new index, using a HNSW index on Cosine Similarity\n",
    "index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "# index.addDataPointBatch(data)\n",
    "# index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "# query for the nearest neighbours of the first datapoint\n",
    "# ids, distances = index.knnQuery(data[0], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "\n",
    "# https://docker-py.readthedocs.io/en/stable/client.html\n",
    "docker_client = docker.from_env()\n",
    "docker_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = docker_client.images.list()\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes2human(input_bytes):\n",
    "    \"\"\"\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    bytes2human(10000) # '9.8K'\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    https://github.com/giampaolo/psutil/blob/master/scripts/meminfo.py\n",
    "    \"\"\"\n",
    "    symbols = ('K', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y')\n",
    "    prefix = {}\n",
    "    for i, s in enumerate(symbols):\n",
    "        prefix[s] = 1 << (i + 1) * 10\n",
    "\n",
    "    for s in reversed(symbols):\n",
    "        if input_bytes >= prefix[s]:\n",
    "            value = input_bytes / prefix[s]\n",
    "            return '%.1f%s' % (value, s)\n",
    "\n",
    "    return '%sB' % input_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "# pip install psutil\n",
    "available_memory = psutil.virtual_memory().available\n",
    "bytes2human(available_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "vec1 = np.array([1.0, 2.0, 3.0])\n",
    "vec2 = np.array([2.0, 5.0, 1.0])\n",
    "vec3 = np.array([3.0, 4.0, 0.0])\n",
    "vec4 = np.array([4.0, 3.0, 2.0])\n",
    "\n",
    "cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - vec1.dot(vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Inner Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python install.py --algo annoy\n",
    "# python install.py --algo nmslib\n",
    "# python install.py --algo faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python run.py --dataset glove-100-angular --algo annoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://cmry.github.io/notes/euclidean-v-cosine\n",
    "- https://stats.stackexchange.com/questions/146221/is-cosine-similarity-identical-to-l2-normalized-euclidean-distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "183px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
